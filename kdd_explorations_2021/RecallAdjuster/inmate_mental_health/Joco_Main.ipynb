{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hemank/.pyenv/versions/3.6.9/lib/python3.6/site-packages/ipykernel_launcher.py:15: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/hemank/.pyenv/versions/3.6.9/lib/python3.6/site-packages/ipykernel_launcher.py:29: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display \n",
    "pd.options.display.max_columns = None\n",
    "%matplotlib inline\n",
    "\n",
    "def connect(poolclass=sqlalchemy.pool.QueuePool):\n",
    "    with open(os.path.join(os.path.join('../../..','config'), 'joco_db_profile.yaml')) as fd:\n",
    "        config = yaml.load(fd)\n",
    "        dburl = sqlalchemy.engine.url.URL(\n",
    "            \"postgres\",\n",
    "            host=config[\"host\"],\n",
    "            username=config[\"user\"],\n",
    "            database=config[\"db\"],\n",
    "            password=config[\"pass\"],\n",
    "            port=config[\"port\"],\n",
    "        )\n",
    "        return sqlalchemy.create_engine(dburl, poolclass=poolclass)\n",
    "\n",
    "    \n",
    "def connect2(poolclass=sqlalchemy.pool.QueuePool):\n",
    "    with open(os.path.join(os.path.join('../../..', 'config'), 'joco_db_profile_old.yaml')) as fd:\n",
    "        config = yaml.load(fd)\n",
    "        dburl = sqlalchemy.engine.url.URL(\n",
    "                \"postgres\",\n",
    "                host = config[\"host\"],\n",
    "                username = config[\"user\"],\n",
    "                database = config[\"db\"],\n",
    "                password = config[\"pass\"],\n",
    "                port = config[\"port\"])\n",
    "        return sqlalchemy.create_engine(dburl, poolclass=poolclass)\n",
    "    \n",
    "    \n",
    "conn = connect()\n",
    "conn2 = connect2()\n",
    "\n",
    "import SAVE_RecallAdjuster as sra\n",
    "from importlib import reload\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Relevant Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2014-04-01', '2014-04-01'), ('2014-04-01', '2015-04-01'), ('2014-08-01', '2014-08-01'), ('2014-08-01', '2015-08-01'), ('2014-12-01', '2014-12-01'), ('2014-12-01', '2015-12-01'), ('2015-04-01', '2015-04-01'), ('2015-04-01', '2016-04-01'), ('2015-08-01', '2015-08-01'), ('2015-08-01', '2016-08-01'), ('2015-12-01', '2015-12-01'), ('2015-12-01', '2016-12-01'), ('2016-04-01', '2016-04-01'), ('2016-04-01', '2017-04-01'), ('2016-08-01', '2016-08-01'), ('2016-08-01', '2017-08-01'), ('2016-12-01', '2016-12-01'), ('2016-12-01', '2017-12-01'), ('2017-04-01', '2017-04-01'), ('2017-04-01', '2018-04-01')]\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "base = datetime.datetime.strptime('2018-04-01', '%Y-%m-%d')\n",
    "date_pairs = []\n",
    "for x in range(9,-1,-1):\n",
    "    date_pairs.append(\n",
    "        (\n",
    "        (base - relativedelta(months=4*x) - relativedelta(years=1)).strftime('%Y-%m-%d'),\n",
    "        (base - relativedelta(months=4*x) - relativedelta(years=1)).strftime('%Y-%m-%d')\n",
    "        )\n",
    "    )\n",
    "    date_pairs.append(\n",
    "        (\n",
    "        (base - relativedelta(months=4*x) - relativedelta(years=1)).strftime('%Y-%m-%d'),\n",
    "        (base - relativedelta(months=4*x)).strftime('%Y-%m-%d')\n",
    "        )\n",
    "    )\n",
    "\n",
    "import seaborn as sns\n",
    "print(date_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Recall Adjusters for different sampling configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "myRA_original = sra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='hemank',\n",
    "        schema='joco_bias_original',\n",
    "        experiment_hashes='922b589d2ddd187665524dab017228c9', #This might have changed.\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500],\n",
    "        entity_demos='hemank_bias_alternatives.currmatch_entity_demos',\n",
    "        #entity_demos='kit_bias_class_test.entity_demos',\n",
    "        demo_col='race_2way'\n",
    ")\n",
    "print(\"Time Taken=\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "myRA_original = sra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='hemank',\n",
    "        schema='joco_bias_nop',\n",
    "        experiment_hashes='b69f9578743dd2bfcb6faee7b06b0b92',\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500],\n",
    "        entity_demos='hemank_bias_alternatives.currmatch_entity_demos',\n",
    "        #entity_demos='kit_bias_class_test.entity_demos',\n",
    "        demo_col='race_2way'\n",
    ")\n",
    "print(\"Time Taken=\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "myRA_original = sra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='hemank',\n",
    "        schema='joco_bias_under_1_orig_orig',\n",
    "        experiment_hashes='5fc43b64d58ae8dc6c3e35e96c684516',\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500],\n",
    "        entity_demos='hemank_bias_alternatives.currmatch_entity_demos',\n",
    "        #entity_demos='kit_bias_class_test.entity_demos',\n",
    "        demo_col='race_2way'\n",
    ")\n",
    "print(\"Time Taken=\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "myRA_original = sra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='hemank',\n",
    "        schema='joco_bias_under_orig_50_50',\n",
    "        experiment_hashes='56c9b82dfd54e893b368859dea4a4c96',\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500],\n",
    "        entity_demos='hemank_bias_alternatives.currmatch_entity_demos',\n",
    "        #entity_demos='kit_bias_class_test.entity_demos',\n",
    "        demo_col='race_2way'\n",
    ")\n",
    "print(\"Time Taken=\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "myRA_original = sra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='hemank',\n",
    "        schema='joco_bias_under_orig_50_orig',\n",
    "        experiment_hashes='c7594f5e9e62b1359076bf924576c436',\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500],\n",
    "        entity_demos='hemank_bias_alternatives.currmatch_entity_demos',\n",
    "        #entity_demos='kit_bias_class_test.entity_demos',\n",
    "        demo_col='race_2way'\n",
    ")\n",
    "print(\"Time Taken=\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to re-run this.\n",
    "start_time = time.time()\n",
    "myRA_original = sra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='hemank',\n",
    "        schema='joco_bias_under_1_50_50',\n",
    "        experiment_hashes='1d118bd0eb09b3d24af029e4f74d658f',\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500],\n",
    "        entity_demos='hemank_bias_alternatives.currmatch_entity_demos',\n",
    "        #entity_demos='kit_bias_class_test.entity_demos',\n",
    "        demo_col='race_2way'\n",
    ")\n",
    "print(\"Time Taken=\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "myRA_original = sra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='hemank',\n",
    "        schema='joco_bias_under_1_same_nop_orig',\n",
    "        experiment_hashes='5fa9d4f74a52ed283230e979b6681aa9',\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500],\n",
    "        entity_demos='hemank_bias_alternatives.currmatch_entity_demos',\n",
    "        #entity_demos='kit_bias_class_test.entity_demos',\n",
    "        demo_col='race_2way'\n",
    ")\n",
    "print(\"Time Taken=\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "myRA_original = sra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='hemank',\n",
    "        schema='joco_bias_over_1_orig_orig',\n",
    "        experiment_hashes='91538d7862f73018583ea200c8b5332d',\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500],\n",
    "        entity_demos='hemank_bias_alternatives.currmatch_entity_demos',\n",
    "        #entity_demos='kit_bias_class_test.entity_demos',\n",
    "        demo_col='race_2way'\n",
    ")\n",
    "print(\"Time Taken=\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "myRA_original = sra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='hemank',\n",
    "        schema='joco_bias_over_orig_50_50',\n",
    "        experiment_hashes='6c9bb810a1cb616d64c8167dbd29dc2d',\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500],\n",
    "        entity_demos='hemank_bias_alternatives.currmatch_entity_demos',\n",
    "        #entity_demos='kit_bias_class_test.entity_demos',\n",
    "        demo_col='race_2way'\n",
    ")\n",
    "print(\"Time Taken=\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "myRA_original = sra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='hemank',\n",
    "        schema='joco_bias_over_orig_50_orig',\n",
    "        experiment_hashes='2e2341b8835b2cd56f0c6f3d387bb6bd',\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500],\n",
    "        entity_demos='hemank_bias_alternatives.currmatch_entity_demos',\n",
    "        #entity_demos='kit_bias_class_test.entity_demos',\n",
    "        demo_col='race_2way'\n",
    ")\n",
    "print(\"Time Taken=\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "myRA_original = sra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='hemank',\n",
    "        schema='joco_bias_over_orig_same_nop_orig',\n",
    "        experiment_hashes='2481f97a89309085c631471df464325d',\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500],\n",
    "        entity_demos='hemank_bias_alternatives.currmatch_entity_demos',\n",
    "        #entity_demos='kit_bias_class_test.entity_demos',\n",
    "        demo_col='race_2way'\n",
    ")\n",
    "print(\"Time Taken=\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "myRA_original = sra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='hemank',\n",
    "        schema='joco_bias_over_1_50_50',\n",
    "        experiment_hashes='8377989ce078dfafdde137ecb3910478',\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500],\n",
    "        entity_demos='hemank_bias_alternatives.currmatch_entity_demos',\n",
    "        #entity_demos='kit_bias_class_test.entity_demos',\n",
    "        demo_col='race_2way'\n",
    ")\n",
    "print(\"Time Taken=\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "myRA_original = sra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='hemank',\n",
    "        schema='joco_bias_over_1_same_nop_orig',\n",
    "        experiment_hashes='a19f07e054456b208ac6b98e1e2f9dc7',\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500],\n",
    "        entity_demos='hemank_bias_alternatives.currmatch_entity_demos',\n",
    "        #entity_demos='kit_bias_class_test.entity_demos',\n",
    "        demo_col='race_2way'\n",
    ")\n",
    "print(\"Time Taken=\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoupled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myRA_decoupled = sra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='rg_staff',\n",
    "        schema='hemank_bias_decoupled',\n",
    "        experiment_hashes='922b589d2ddd187665524dab017228c9',\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500],\n",
    "        #entity_demos='joco',\n",
    "        entity_demos='hemank_bias_alternatives.currmatch_entity_demos',\n",
    "        demo_col='race_2way',\n",
    "        decoupled_experiments=[\n",
    "            ('7919a4a22d4ed46d199e9387b99bcffd', 'White'), \n",
    "            ('48776f644a102217c57e2ca6724c614b', 'NonWhite')],\n",
    "        decoupled_entity_demos='hemank_bias_alternatives.currmatch_entity_demos'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zafar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "myRA_original = sra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='hemank',\n",
    "        schema='joco_bias_zafar',\n",
    "        experiment_hashes='',\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500],\n",
    "        entity_demos='hemank_bias_alternatives.currmatch_entity_demos',\n",
    "        #entity_demos='kit_bias_class_test.entity_demos',\n",
    "        demo_col='race_2way'\n",
    ")\n",
    "print(\"Time Taken=\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = Template(\"\"\"\n",
    "WITH mg_rns AS (\n",
    "  SELECT *,\n",
    "         row_number() OVER (PARTITION BY train_end_time, list_size, metric, parameter ORDER BY base_value DESC, base_max_recall_ratio ASC, RANDOM()) AS rn_base,\n",
    "         row_number() OVER (PARTITION BY train_end_time, list_size, metric, parameter ORDER BY adj_value DESC, adj_max_recall_ratio ASC, RANDOM()) AS rn_adj\n",
    "  FROM {{schema}}.model_adjustment_results_race_2way\n",
    "  WHERE past_train_end_time = train_end_time\n",
    ")\n",
    ", base_mgs AS (\n",
    "  SELECT * FROM mg_rns WHERE rn_base = 1\n",
    ")\n",
    ", adj_mgs AS (\n",
    "  SELECT * FROM mg_rns WHERE rn_adj = 1\n",
    ")\n",
    "\n",
    "-- Simple model selection on last time period, baseline with no recall adjustments\n",
    "SELECT 'Best Unadjusted Metric - Unadjusted'::VARCHAR(128) AS strategy,\n",
    "       r.train_end_time, r.past_train_end_time,\n",
    "       r.list_size, r.metric, r.parameter,\n",
    "       r.base_value AS value,\n",
    "       r.base_max_recall_ratio AS max_recall_ratio,\n",
    "       r.base_recall_white_to_nonwhite AS recall_w_to_nw,\n",
    "       r.base_recall_nonwhite_to_white AS recall_nw_to_w\n",
    "FROM {{schema}}.model_adjustment_results_race_2way r\n",
    "JOIN base_mgs b\n",
    "  ON r.model_group_id = b.model_group_id\n",
    "  AND r.past_train_end_time = b.train_end_time\n",
    "  AND r.list_size = b.list_size\n",
    "  AND r.metric = b.metric\n",
    "  AND r.parameter = b.parameter\n",
    "WHERE r.train_end_time > r.past_train_end_time\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "-- Model selection on last time before adjustment, with adjustment applied\n",
    "SELECT 'Best Unadjusted Metric - Adjusted'::VARCHAR(128) AS strategy,\n",
    "       r.train_end_time, r.past_train_end_time,\n",
    "       r.list_size, r.metric, r.parameter,\n",
    "       r.adj_value AS value,\n",
    "       r.adj_max_recall_ratio AS max_recall_ratio,\n",
    "       r.adj_recall_white_to_nonwhite AS recall_w_to_nw,\n",
    "       r.adj_recall_nonwhite_to_white AS recall_nw_to_w\n",
    "FROM {{schema}}.model_adjustment_results_race_2way r\n",
    "JOIN base_mgs b\n",
    "  ON r.model_group_id = b.model_group_id\n",
    "  AND r.past_train_end_time = b.train_end_time\n",
    "  AND r.list_size = b.list_size\n",
    "  AND r.metric = b.metric\n",
    "  AND r.parameter = b.parameter\n",
    "WHERE r.train_end_time > r.past_train_end_time\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "-- Model selection on last time after adjustment, with adjustment applied\n",
    "SELECT 'Best Adjusted Metric - Adjusted'::VARCHAR(128) AS strategy,\n",
    "       r.train_end_time, r.past_train_end_time,\n",
    "       r.list_size, r.metric, r.parameter,\n",
    "       r.adj_value AS value,\n",
    "       r.adj_max_recall_ratio AS max_recall_ratio,\n",
    "       r.adj_recall_white_to_nonwhite AS recall_w_to_nw,\n",
    "       r.adj_recall_nonwhite_to_white AS recall_nw_to_w\n",
    "FROM {{schema}}.model_adjustment_results_race_2way r\n",
    "JOIN adj_mgs b\n",
    "  ON r.model_group_id = b.model_group_id\n",
    "  AND r.past_train_end_time = b.train_end_time\n",
    "  AND r.list_size = b.list_size\n",
    "  AND r.metric = b.metric\n",
    "  AND r.parameter = b.parameter\n",
    "WHERE r.train_end_time > r.past_train_end_time\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "-- Composite model\n",
    "SELECT 'Composite Model - Adjusted'::VARCHAR(128) AS strategy,\n",
    "      r.train_end_time AS train_end_time,\n",
    "      r.past_train_end_time AS past_train_end_time,\n",
    "      r.list_size, metric, parameter,\n",
    "      r.value AS value,\n",
    "      r.max_recall_ratio AS max_recall_ratio,\n",
    "      r.recall_white_to_nonwhite AS recall_w_to_nw,\n",
    "      r.recall_nonwhite_to_white AS recall_nw_to_w\n",
    "FROM {{schema}}.composite_results_race_2way r\n",
    "WHERE train_end_time > past_train_end_time\n",
    ";\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_decoupled = Template(\"\"\"\n",
    "WITH mg_rns AS (\n",
    "  SELECT *,\n",
    "         row_number() OVER (PARTITION BY train_end_time, list_size, metric, parameter ORDER BY base_value DESC, base_max_recall_ratio ASC, RANDOM()) AS rn_base,\n",
    "         row_number() OVER (PARTITION BY train_end_time, list_size, metric, parameter ORDER BY adj_value DESC, adj_max_recall_ratio ASC, RANDOM()) AS rn_adj\n",
    "  FROM {{schema}}.model_adjustment_results_race_2way\n",
    "  WHERE past_train_end_time = train_end_time\n",
    ")\n",
    ", base_mgs AS (\n",
    "  SELECT * FROM mg_rns WHERE rn_base = 1\n",
    ")\n",
    ", adj_mgs AS (\n",
    "  SELECT * FROM mg_rns WHERE rn_adj = 1\n",
    ")\n",
    "\n",
    "\n",
    "-- -- Composite model (with decoupled models)\n",
    "SELECT 'Composite w/ Decoupled - Adjusted'::VARCHAR(128) AS strategy,\n",
    "      train_end_time, past_train_end_time,\n",
    "      list_size, metric, parameter,\n",
    "      value,\n",
    "      max_recall_ratio,\n",
    "      recall_white_to_nonwhite AS recall_w_to_nw,\n",
    "      recall_nonwhite_to_white AS recall_nw_to_w\n",
    "FROM {{schema}}.composite_results_decoupled_race_2way\n",
    "WHERE train_end_time > past_train_end_time\n",
    ";\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['schema'] = 'joco_bias_original'\n",
    "sql_orig = query.render(**params)\n",
    "ts_df_orig = pd.read_sql(sql_orig, conn)\n",
    "\n",
    "params['schema'] = 'joco_bias_nop'\n",
    "sql_us = query.render(**params)\n",
    "ts_df_nop = pd.read_sql(sql_us, conn)\n",
    "\n",
    "params['schema'] = 'joco_zafar'\n",
    "sql_zafar = query.render(**params)\n",
    "ts_df_zafar = pd.read_sql(sql_zafar, conn)\n",
    "\n",
    "params['schema'] = 'joco_bias_decoupled'\n",
    "sql_decoupled = query_decoupled.render(**params)\n",
    "ts_df_decoupled = pd.read_sql(sql_decoupled, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersampling\n",
    "params = {}\n",
    "params['schema'] = 'joco_bias_under_1_orig_orig'\n",
    "sql_orig = query.render(**params)\n",
    "ts_df_u_v1a = pd.read_sql(sql_orig, conn)\n",
    "\n",
    "params['schema'] = 'joco_bias_under_orig_50_50'\n",
    "sql_us = query.render(**params)\n",
    "ts_df_u_v2a = pd.read_sql(sql_us, conn)\n",
    "\n",
    "params['schema'] = 'joco_bias_under_orig_same_nop_orig'\n",
    "sql_us = query.render(**params)\n",
    "ts_df_u_v2b = pd.read_sql(sql_us, conn)\n",
    "\n",
    "params['schema'] = 'joco_bias_under_orig_50_orig'\n",
    "sql_us = query.render(**params)\n",
    "ts_df_u_v2c = pd.read_sql(sql_us, conn)\n",
    "\n",
    "params['schema'] = 'joco_bias_under_1_50_50'\n",
    "sql_us = query.render(**params)\n",
    "ts_df_u_v3a = pd.read_sql(sql_us, conn)\n",
    "\n",
    "params['schema'] = 'joco_bias_under_1_same_nop_orig'\n",
    "sql_us = query.render(**params)\n",
    "ts_df_u_v3b = pd.read_sql(sql_us, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling\n",
    "params = {}\n",
    "params['schema'] = 'joco_bias_over_1_orig_orig'\n",
    "sql_os = query.render(**params)\n",
    "ts_df_o_v1a = pd.read_sql(sql_os, conn)\n",
    "\n",
    "params['schema'] = 'joco_bias_over_orig_50_50'\n",
    "sql_os = query.render(**params)\n",
    "ts_df_o_v2a = pd.read_sql(sql_os, conn)\n",
    "\n",
    "params['schema'] = 'joco_bias_over_orig_same_nop_orig'\n",
    "sql_os = query.render(**params)\n",
    "ts_df_o_v2b = pd.read_sql(sql_os, conn)\n",
    "\n",
    "params['schema'] = 'joco_bias_over_orig_50_orig'\n",
    "sql_os = query.render(**params)\n",
    "ts_df_o_v2c = pd.read_sql(sql_os, conn)\n",
    "\n",
    "params['schema'] = 'joco_bias_over_1_50_50'\n",
    "sql_os = query.render(**params)\n",
    "ts_df_o_v3a = pd.read_sql(sql_os, conn)\n",
    "\n",
    "params['schema'] = 'joco_bias_over_1_same_nop_orig'\n",
    "sql_os = query.render(**params)\n",
    "ts_df_o_v3b = pd.read_sql(sql_os, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df_u_v1a['dataset'] = 'Under-v1a'\n",
    "u_v1a_df = ts_df_u_v1a.rename(\n",
    "    {'recall_w_to_nw': 'recall_disp', \n",
    "     'frac_white': 'frac_grp1', \n",
    "     'frac_nonwhite': 'frac_grp2'\n",
    "    }, axis='columns')\n",
    "\n",
    "ts_df_u_v2a['dataset'] = 'Under-v2a'\n",
    "u_v2a_df = ts_df_u_v2a.rename(\n",
    "    {'recall_w_to_nw': 'recall_disp', \n",
    "     'frac_white': 'frac_grp1', \n",
    "     'frac_nonwhite': 'frac_grp2'\n",
    "    }, axis='columns')\n",
    "\n",
    "ts_df_u_v2b['dataset'] = 'Under-v2b'\n",
    "u_v2b_df = ts_df_u_v2b.rename(\n",
    "    {'recall_w_to_nw': 'recall_disp', \n",
    "     'frac_white': 'frac_grp1', \n",
    "     'frac_nonwhite': 'frac_grp2'\n",
    "    }, axis='columns')\n",
    "\n",
    "ts_df_u_v2c['dataset'] = 'Under-v2c'\n",
    "u_v2c_df = ts_df_u_v2c.rename(\n",
    "    {'recall_w_to_nw': 'recall_disp', \n",
    "     'frac_white': 'frac_grp1', \n",
    "     'frac_nonwhite': 'frac_grp2'\n",
    "    }, axis='columns')\n",
    "\n",
    "ts_df_u_v3a['dataset'] = 'Under-v3a'\n",
    "u_v3a_df = ts_df_u_v3a.rename(\n",
    "    {'recall_w_to_nw': 'recall_disp', \n",
    "     'frac_white': 'frac_grp1', \n",
    "     'frac_nonwhite': 'frac_grp2'\n",
    "    }, axis='columns')\n",
    "\n",
    "ts_df_u_v3b['dataset'] = 'Under-v3b'\n",
    "u_v3b_df = ts_df_u_v3b.rename(\n",
    "    {'recall_w_to_nw': 'recall_disp', \n",
    "     'frac_white': 'frac_grp1', \n",
    "     'frac_nonwhite': 'frac_grp2'\n",
    "    }, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df_o_v1a['dataset'] = 'Over-v1a'\n",
    "o_v1a_df = ts_df_o_v1a.rename(\n",
    "    {'recall_w_to_nw': 'recall_disp', \n",
    "     'frac_white': 'frac_grp1', \n",
    "     'frac_nonwhite': 'frac_grp2'\n",
    "    }, axis='columns')\n",
    "\n",
    "ts_df_o_v2a['dataset'] = 'Over-v2a'\n",
    "o_v2a_df = ts_df_o_v2a.rename(\n",
    "    {'recall_w_to_nw': 'recall_disp', \n",
    "     'frac_white': 'frac_grp1', \n",
    "     'frac_nonwhite': 'frac_grp2'\n",
    "    }, axis='columns')\n",
    "\n",
    "ts_df_o_v2c['dataset'] = 'Over-v2c'\n",
    "o_v2c_df = ts_df_o_v2c.rename(\n",
    "    {'recall_w_to_nw': 'recall_disp', \n",
    "     'frac_white': 'frac_grp1', \n",
    "     'frac_nonwhite': 'frac_grp2'\n",
    "    }, axis='columns')\n",
    "\n",
    "ts_df_o_v2b['dataset'] = 'Over-v2b'\n",
    "o_v2b_df = ts_df_o_v2b.rename(\n",
    "    {'recall_w_to_nw': 'recall_disp', \n",
    "     'frac_white': 'frac_grp1', \n",
    "     'frac_nonwhite': 'frac_grp2'\n",
    "    }, axis='columns')\n",
    "\n",
    "ts_df_o_v3a['dataset'] = 'Over-v3a'\n",
    "o_v3a_df = ts_df_o_v3a.rename(\n",
    "    {'recall_w_to_nw': 'recall_disp', \n",
    "     'frac_white': 'frac_grp1', \n",
    "     'frac_nonwhite': 'frac_grp2'\n",
    "    }, axis='columns')\n",
    "\n",
    "ts_df_o_v3b['dataset'] = 'Over-v3b'\n",
    "o_v3b_df = ts_df_o_v3b.rename(\n",
    "    {'recall_w_to_nw': 'recall_disp', \n",
    "     'frac_white': 'frac_grp1', \n",
    "     'frac_nonwhite': 'frac_grp2'\n",
    "    }, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zafar_df = ts_df_zafar.rename(\n",
    "    {'recall_w_to_nw': 'recall_disp',\n",
    "    'frac_white': 'frac_grp1',\n",
    "    'frac_nonwhite': 'frac_grp2'\n",
    "    }, axis='columns')\n",
    "zafar_df['dataset'] = 'Zafar'\n",
    "\n",
    "ts_df_orig['dataset'] = 'Original'\n",
    "orig_df = ts_df_orig.rename(\n",
    "    {'recall_w_to_nw': 'recall_disp', \n",
    "     'frac_white': 'frac_grp1', \n",
    "     'frac_nonwhite': 'frac_grp2'\n",
    "    }, axis='columns')\n",
    "\n",
    "ts_df_nop['dataset'] = 'NoP'\n",
    "nop_df = ts_df_nop.rename(\n",
    "    {'recall_w_to_nw': 'recall_disp', \n",
    "     'frac_white': 'frac_grp1', \n",
    "     'frac_nonwhite': 'frac_grp2'\n",
    "    }, axis='columns')\n",
    "\n",
    "ts_df_decoupled['dataset'] = 'Decoupled'\n",
    "decoupled_df = ts_df_decoupled.rename(\n",
    "    {'recall_w_to_nw': 'recall_disp',\n",
    "     'frac_white': 'frac_grp1',\n",
    "     'frac_nonwhite':'frac_grp2'\n",
    "    }, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure_two(comp_df):\n",
    "    colorlist = sns.color_palette(\"dark\", 12).as_hex()\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    data = comp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reindex([\"Original\", \"No Protected\", \n",
    "                                                                                        \"Sampling (Best Equity)\",\n",
    "                                                                                       \"Sampling (Best Precision)\",\n",
    "                                                                                       \"Composite Adjusted\",\n",
    "                                                                                       \"Regularization\", \n",
    "                                                                                  \"Post-hoc Adjustment\"]).reset_index()\n",
    "\n",
    "    unique_dfs = [\"Original\", \"No Protected\", \"Sampling (Best Equity)\", \"Sampling (Best Precision)\",\n",
    "                 \"Composite Adjusted\", \"Regularization\", \"Post-hoc Adjustment\"]\n",
    "    \n",
    "    colorlist = ['#001c7f', #Original\n",
    "                 '#b1400d', #No_Protected\n",
    "                 '#12711c', #Best Sampling(Equity)\n",
    "                 #'#8c0800', #OLD -Best Sampling(Precision)\n",
    "                 '#7CFC00', #NEW - Best Sampling(Precision)\n",
    "                 '#591e71', #Composite Adjustment\n",
    "                 '#592f0d', #Regularization\n",
    "                 '#a23582' #Post-hoc Adjustment\n",
    "                ]\n",
    "\n",
    "    \n",
    "    sns.lineplot(data = data,\n",
    "                 x='value', y='recall_disp',\n",
    "                 hue = 'dataset',\n",
    "                 markers = True,\n",
    "                 palette = colorlist,\n",
    "                 linewidth = 20.0,\n",
    "                 marker = \"o\",\n",
    "                 markersize = 12,\n",
    "                 dashes = None,\n",
    "                 ci = None,\n",
    "                 ax = ax)\n",
    "    \n",
    "    #unique_dfs = np.unique(data['dataset'])\n",
    "    \n",
    "    for i in range(len(unique_dfs)):\n",
    "        tmp_df = comp_df.loc[comp_df['dataset'] == unique_dfs[i], ].copy()\n",
    "        \n",
    "        x_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['value'].values)\n",
    "        y_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['recall_disp'].values)\n",
    "        \n",
    "        prec_errors = 1.96*tmp_df.groupby(['dataset'])['value'].sem().values\n",
    "        disp_errors = 1.96*tmp_df.groupby(['dataset'])['recall_disp'].sem().values\n",
    "        \n",
    "        color = colorlist[i]\n",
    "        \n",
    "        ax.errorbar(x_coords, y_coords,\n",
    "                   xerr = prec_errors,\n",
    "                   yerr = disp_errors,\n",
    "                   ecolor = colorlist[i], fmt= ' ', zorder=-1, capsize=5, linewidth=3.0)\n",
    "        \n",
    "    ax.set_ylabel('Recall Disparity', fontsize=32)\n",
    "    ax.set_xlabel('Precision at Top-K', fontsize=28)\n",
    "    ax.set_xlim([0.5,0.58])\n",
    "    ax.plot([0.0,1.0],[1.0, 1.0], linestyle = '--', color='black')\n",
    "    \n",
    "    ax.tick_params(axis='x', labelsize=24)\n",
    "    ax.tick_params(axis='y', labelsize=24)\n",
    "\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    hhandles = []\n",
    "    llabels = []\n",
    "\n",
    "    for i, lab in enumerate(labels):\n",
    "        #if lab not in list(unique_dfs):# + ['dataset']:\n",
    "        #    handles[i].set_linestyle(\"\")\n",
    "        if lab not in list(unique_dfs):\n",
    "            handles[i].set_linestyle(\"\")\n",
    "            lab = \"Methods\"\n",
    "        hhandles.append(handles[i])\n",
    "        llabels.append(lab)\n",
    "\n",
    "    #ax.legend(hhandles, llabels, fontsize=16, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., markerscale=2)\n",
    "    ax.set_xlim([0.5, 0.58])\n",
    "    ax.get_legend().remove()\n",
    "    #print(hhandles)\n",
    "    #print(llabels)\n",
    "    #ax.legend(hhandles, llabels, fontsize=16, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., markerscale=2)\n",
    "    ax.legend(handles[1:], labels[1:], fontsize=16,\n",
    "              bbox_to_anchor=(0, 5), loc='upper center', ncol=7, markerscale=20.0)\n",
    "    \n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig_two_df = pd.concat([orig_df, nop_df, zafar_df, decoupled_df])\n",
    "\n",
    "filtered_original_df = orig_df[(orig_df['strategy'] == 'Best Unadjusted Metric - Unadjusted')]\n",
    "filtered_original_df.loc[:,'dataset'] = 'Original'\n",
    "filtered_original_df.loc[:,'strategy'] = 'No Adjustment'\n",
    "\n",
    "filtered_adjusted_df = orig_df[(orig_df['strategy'] == 'Best Unadjusted Metric - Adjusted')]\n",
    "filtered_adjusted_df.loc[:,'dataset'] = 'Post-hoc Adjustment'\n",
    "filtered_adjusted_df.loc[:,'strategy'] = 'Post-hoc Adjustment'\n",
    "\n",
    "filtered_composite_df = orig_df[(orig_df['strategy'] == 'Composite Model - Adjusted')]\n",
    "filtered_composite_df.loc[:,'dataset'] = 'Composite Adjusted'\n",
    "filtered_composite_df.loc[:,'strategy'] = 'Composite Adjusted'\n",
    "\n",
    "filtered_nop_df = nop_df[nop_df['strategy'] == 'Best Unadjusted Metric - Unadjusted']\n",
    "filtered_nop_df.loc[:,'dataset'] = 'No Protected'\n",
    "filtered_nop_df.loc[:,'strategy'] = 'No Protected'\n",
    "\n",
    "filtered_zafar_df = zafar_df[zafar_df['strategy'] == 'Best Unadjusted Metric - Unadjusted']\n",
    "filtered_zafar_df.loc[:,'dataset'] = 'Regularization'\n",
    "filtered_zafar_df.loc[:,'strategy'] = 'Regularization'\n",
    "\n",
    "best_prec_df = u_v3b_df[u_v3b_df['strategy'] == 'Best Unadjusted Metric - Unadjusted']\n",
    "best_prec_df.loc[:,'dataset'] = 'Sampling (Best Precision)'\n",
    "best_prec_df.loc[:,'strategy'] = 'Sampling (Best Precision)'\n",
    "\n",
    "best_equity_df = o_v2a_df[o_v2a_df['strategy'] == 'Best Unadjusted Metric - Unadjusted']\n",
    "best_equity_df.loc[:,'dataset'] = 'Sampling (Best Equity)'\n",
    "best_equity_df.loc[:,'strategy'] = 'Sampling (Best Equity)'\n",
    "\n",
    "fig_two_df = pd.concat([filtered_original_df, filtered_nop_df, filtered_zafar_df, \n",
    "                        best_prec_df, best_equity_df, filtered_adjusted_df,\n",
    "                       filtered_composite_df])\n",
    "\n",
    "fig_three_df = pd.concat([filtered_original_df, filtered_nop_df])\n",
    "fig_four_df = pd.concat([filtered_original_df, filtered_zafar_df])\n",
    "\n",
    "filtered_decoupled_df = decoupled_df[(decoupled_df['strategy'] == 'Composite w/ Decoupled - Adjusted')]\n",
    "filtered_decoupled_df.loc[:,'strategy'] = 'Decoupled'\n",
    "filtered_decoupled_df.loc[:,'dataset'] = 'Decoupled'\n",
    "\n",
    "fig_five_df = pd.concat([filtered_original_df, filtered_composite_df, filtered_decoupled_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_two(fig_two_df)\n",
    "plt.savefig('../../PLOTS2/PLOTS_Summary/JoCo_Methods_NEW.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure_three(comp_df):\n",
    "    colorlist = sns.color_palette(\"dark\", 12).as_hex()\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    data = comp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reindex([\"Original\", \"No Protected\"]\n",
    "                                                                                ).reset_index()\n",
    "    colorlist = ['#001c7f', #Original\n",
    "                 '#b1400d']\n",
    "    unique_dfs = [\"Original\", \"No Protected\"]\n",
    "    \n",
    "    sns.lineplot(data = data,\n",
    "                 x='value', y='recall_disp',\n",
    "                 hue = 'dataset',\n",
    "                 markers = True,\n",
    "                 palette = colorlist,\n",
    "                 marker = \"o\",\n",
    "                 markersize = 10,\n",
    "                 dashes = None,\n",
    "                 ci = None,\n",
    "                 ax = ax)\n",
    "    \n",
    "    unique_dfs = [\"Original\", \"No Protected\"]\n",
    "        \n",
    "    for i in range(len(unique_dfs)):\n",
    "        tmp_df = comp_df.loc[comp_df['dataset'] == unique_dfs[i], ].copy()\n",
    "        \n",
    "        x_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['value'].values)\n",
    "        y_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['recall_disp'].values)\n",
    "        \n",
    "        prec_errors = 1.96*tmp_df.groupby(['dataset'])['value'].sem().values\n",
    "        disp_errors = 1.96*tmp_df.groupby(['dataset'])['recall_disp'].sem().values\n",
    "        \n",
    "        color = colorlist[i]\n",
    "        \n",
    "        ax.errorbar(x_coords, y_coords,\n",
    "                   xerr = prec_errors,\n",
    "                   yerr = disp_errors,\n",
    "                   ecolor = colorlist[i], fmt= ' ', zorder=-1, capsize=5, linewidth=3.0)\n",
    "        \n",
    "    ax.set_ylabel('Recall Disparity', fontsize=32)\n",
    "    ax.set_xlabel('Precision at Top-K', fontsize=28)\n",
    "    ax.plot([0.0,1.0],[1.0, 1.0], linestyle = '--', color='black')\n",
    "    \n",
    "    ax.tick_params(axis='x', labelsize=24)\n",
    "    ax.tick_params(axis='y', labelsize=24)\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    hhandles = []\n",
    "    llabels = []\n",
    "\n",
    "    for i, lab in enumerate(labels):\n",
    "        #if lab not in list(unique_dfs):# + ['dataset']:\n",
    "        #    handles[i].set_linestyle(\"\")\n",
    "        if lab not in list(unique_dfs):\n",
    "            handles[i].set_linestyle(\"\")\n",
    "            lab = \"Methods\"\n",
    "        hhandles.append(handles[i])\n",
    "        llabels.append(lab)\n",
    "\n",
    "    ax.legend(hhandles[1:], llabels[1:], fontsize=24, \n",
    "              bbox_to_anchor=(0.025, 0.1), \n",
    "              loc='lower left', \n",
    "              borderaxespad=0., markerscale=2, ncol=1)\n",
    "    ax.set_xlim([0.52, 0.58])\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_three(fig_three_df)\n",
    "plt.savefig('../../PLOTS2/PLOTS_NOP/NoP_JoCo.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure_four(comp_df):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    data = comp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reindex([\"Original\", \"Regularization\"]\n",
    "                                                                                ).reset_index()\n",
    "    colorlist = ['#001c7f', '#592f0d'] #Regularization\n",
    "    \n",
    "    unique_dfs = [\"Original\", \"Regularization\"]\n",
    "\n",
    "    sns.lineplot(data = data,\n",
    "                 x='value', y='recall_disp',\n",
    "                 hue = 'dataset',\n",
    "                 markers = True,\n",
    "                 palette = colorlist,\n",
    "                 linewidth = 20.0,\n",
    "                 marker = \"o\",\n",
    "                 markersize = 10,\n",
    "                 dashes = None,\n",
    "                 ci = None,\n",
    "                 ax = ax)\n",
    "    \n",
    "    for i in range(len(unique_dfs)):\n",
    "        tmp_df = comp_df.loc[comp_df['dataset'] == unique_dfs[i], ].copy()        \n",
    "        x_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['value'].values)\n",
    "        y_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['recall_disp'].values)\n",
    "        \n",
    "        prec_errors = 1.96*tmp_df.groupby(['dataset'])['value'].sem().values\n",
    "        disp_errors = 1.96*tmp_df.groupby(['dataset'])['recall_disp'].sem().values\n",
    "        \n",
    "        color = colorlist[i]\n",
    "    \n",
    "        ax.errorbar(x_coords, y_coords,\n",
    "                   xerr = prec_errors,\n",
    "                   yerr = disp_errors,\n",
    "                   ecolor = colorlist[i], fmt= ' ', zorder=-1, capsize=5, linewidth=3.0)\n",
    "        \n",
    "    ax.set_ylabel('Recall Disparity', fontsize=32)\n",
    "    ax.set_xlabel('Precision at Top-K', fontsize=28)\n",
    "    ax.plot([0.0,1.0],[1.0, 1.0], linestyle = '--', color='black')\n",
    "    \n",
    "    ax.tick_params(axis='x', labelsize=24)\n",
    "    ax.tick_params(axis='y', labelsize=24)\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    hhandles = []\n",
    "    llabels = []\n",
    "\n",
    "    for i, lab in enumerate(labels):\n",
    "        #if lab not in list(unique_dfs):# + ['dataset']:\n",
    "        #    handles[i].set_linestyle(\"\")\n",
    "        if lab not in list(unique_dfs):\n",
    "            handles[i].set_linestyle(\"\")\n",
    "            lab = \"Methods\"\n",
    "        hhandles.append(handles[i])\n",
    "        llabels.append(lab)\n",
    "\n",
    "    ax.legend(hhandles[1:], llabels[1:], fontsize=24, \n",
    "              bbox_to_anchor=(0.015, 0.95), \n",
    "              loc='upper left', \n",
    "              borderaxespad=0., markerscale=2, ncol=1)\n",
    "\n",
    "    ax.set_xlim([0.52, 0.58])\n",
    "    ax.set_ylim([0.9, 1.8])\n",
    "    ax.plot([0.5, 0.6], [1.0, 1.0], color='black', linestyle='--')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_four(fig_four_df)\n",
    "plt.savefig('../../PLOTS2/PLOTS_Zafar/joco_zafar.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure_five(comp_df):\n",
    "    colorlist = sns.color_palette(\"dark\", 12).as_hex()\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    data = comp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reindex([\"Original\", \"Composite Adjusted\", \"Decoupled\"]\n",
    "                                                                                ).reset_index()\n",
    "\n",
    "    colorlist = ['#001c7f', #Original\n",
    "                 '#591e71', # Composite Adjustment\n",
    "                 '#3c3c3c' # Decoupled\n",
    "                ]\n",
    "\n",
    "    sns.lineplot(data = data,\n",
    "                 x='value', y='recall_disp',\n",
    "                 hue = 'dataset',\n",
    "                 markers = True,\n",
    "                 palette = colorlist,\n",
    "                 marker = \"o\",\n",
    "                 markersize = 10,\n",
    "                 dashes = None,\n",
    "                 ci = None,\n",
    "                 ax = ax)\n",
    "    \n",
    "    unique_dfs = [\"Original\", \"Composite Adjusted\", \"Decoupled\"]\n",
    "    \n",
    "    for i in range(len(unique_dfs)):\n",
    "        tmp_df = comp_df.loc[comp_df['dataset'] == unique_dfs[i], ].copy()\n",
    "        \n",
    "        x_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['value'].values)\n",
    "        y_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['recall_disp'].values)\n",
    "        \n",
    "        prec_errors = 1.96*tmp_df.groupby(['dataset'])['value'].sem().values\n",
    "        disp_errors = 1.96*tmp_df.groupby(['dataset'])['recall_disp'].sem().values\n",
    "        \n",
    "        color = colorlist[i]\n",
    "        \n",
    "        ax.errorbar(x_coords, y_coords,\n",
    "                   xerr = prec_errors,\n",
    "                   yerr = disp_errors,\n",
    "                   ecolor = colorlist[i], fmt= ' ', zorder=-1, capsize=5)\n",
    "        \n",
    "    ax.set_ylabel('Recall Disparity', fontsize=32)\n",
    "    ax.set_xlabel('Precision at Top-K', fontsize=28)\n",
    "    ax.plot([0.0,1.0],[1.0, 1.0], linestyle = '--', color='black')\n",
    "    \n",
    "    ax.tick_params(axis='x', labelsize=24)\n",
    "    ax.tick_params(axis='y', labelsize=24)\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    hhandles = []\n",
    "    llabels = []\n",
    "\n",
    "    for i, lab in enumerate(labels):\n",
    "        #if lab not in list(unique_dfs):# + ['dataset']:\n",
    "        #    handles[i].set_linestyle(\"\")\n",
    "        if lab not in list(unique_dfs):\n",
    "            handles[i].set_linestyle(\"\")\n",
    "            lab = \"Methods\"\n",
    "        hhandles.append(handles[i])\n",
    "        llabels.append(lab)\n",
    "\n",
    "    ax.legend(hhandles[1:], llabels[1:], fontsize=20, \n",
    "              bbox_to_anchor=(0.015, 0.975), \n",
    "              loc='upper left', \n",
    "              borderaxespad=0., markerscale=2, ncol=1)\n",
    "\n",
    "    ax.set_ylim([0.9, 1.65])\n",
    "    ax.set_xlim([0.5, 0.58])\n",
    "    ax.plot([0.1, 0.9], [1.0, 1.0], color='black', linestyle='--')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_five(fig_five_df)\n",
    "plt.savefig('../../PLOTS2/PLOTS_Composite/Composite_Joco.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode(x):\n",
    "    if \"Original\" in x:\n",
    "        return \"Original\"\n",
    "    elif \"U\" in x:\n",
    "        return \"Under\"\n",
    "    return \"Over\"\n",
    "\n",
    "usamp_df = pd.concat([u_v1a_df, u_v2a_df, u_v2b_df, u_v2c_df, u_v3a_df, u_v3b_df])\n",
    "osamp_df = pd.concat([o_v1a_df, o_v2a_df, o_v2b_df, o_v2c_df, o_v3a_df, o_v3b_df])\n",
    "\n",
    "filtered_orig_df = orig_df[(orig_df['strategy'] == 'Best Unadjusted Metric - Unadjusted')]\n",
    "filtered_usamp_df = usamp_df[(usamp_df['strategy'] == 'Best Unadjusted Metric - Unadjusted')]\n",
    "filtered_osamp_df = osamp_df[(osamp_df['strategy'] == 'Best Unadjusted Metric - Unadjusted')]\n",
    "\n",
    "fig_six_df = pd.concat([filtered_orig_df, filtered_usamp_df, filtered_osamp_df])\n",
    "fig_six_df.loc[fig_six_df['strategy']=='Best Unadjusted Metric - Unadjusted', 'strategy'] = 'No Adjustment'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Original', 'mode'] = 'Original'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v1a', 'mode'] = 'Under'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v1a', 'dataset'] = '1'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v2a', 'mode'] = 'Under'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v2a', 'dataset'] = '2'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v2b', 'mode'] = 'Under'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v2b', 'dataset'] = '3'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v2c', 'mode'] = 'Under'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v2c', 'dataset'] = '4'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v3a', 'mode'] = 'Under'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v3a', 'dataset'] = '5'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v3b', 'mode'] = 'Under'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v3b', 'dataset'] = '6'\n",
    "\n",
    "fig_six_df.loc[fig_six_df['strategy']=='Best Unadjusted Metric - Unadjusted', 'strategy'] = 'No Adjustment'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v1a', 'mode'] = 'Over'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v1a', 'dataset'] = '1'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v2a', 'mode'] = 'Over'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v2a', 'dataset'] = '2'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v2b', 'mode'] = 'Over'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v2b', 'dataset'] = '3'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v2c', 'mode'] = 'Over'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v2c', 'dataset'] = '4'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v3a', 'mode'] = 'Over'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v3a', 'dataset'] = '5'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v3b', 'mode'] = 'Over'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v3b', 'dataset'] = '6'\n",
    "\n",
    "fig_six_df = fig_six_df.rename(columns={\"dataset\": \"Method\", \"mode\":\"Mode\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_six_df.groupby(['Method', 'Mode'])[['value', 'recall_disp']].mean().reindex([\n",
    "        (\"Original\", \"Original\"),\n",
    "        (\"1\", \"Under\"), (\"2\", \"Under\"), (\"3\", \"Under\"),\n",
    "        (\"4\", \"Under\"), (\"5\", \"Under\"), (\"6\", \"Under\"), \n",
    "        (\"1\", \"Over\"), (\"2\", \"Over\"), (\"3\", \"Over\"), \n",
    "        (\"4\", \"Over\"), (\"5\", \"Over\"), (\"6\", \"Over\")]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure_six(comp_df):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    colorlist = ['#001c7f', #Original\n",
    "                 '#12711c', \n",
    "                 #'#23fab9', \n",
    "                 #'#00875e',\n",
    "                 #'#3fb9c4',\n",
    "                 '#a2ff00']\n",
    "                 #'#688c29']\n",
    "    \n",
    "    data = comp_df.groupby(['Method', 'Mode'])[['value', 'recall_disp']].mean().reindex([\n",
    "        (\"Original\", \"Original\"),\n",
    "        (\"1\", \"Under\"), (\"2\", \"Under\"), (\"3\", \"Under\"),\n",
    "        (\"4\", \"Under\"), (\"5\", \"Under\"), (\"6\", \"Under\"), \n",
    "        (\"1\", \"Over\"), (\"2\", \"Over\"), (\"3\", \"Over\"), \n",
    "        (\"4\", \"Over\"), (\"5\", \"Over\"), (\"6\", \"Over\")]).reset_index()\n",
    "    \n",
    "    sns.lineplot(data = data,\n",
    "                 x='value', y='recall_disp',\n",
    "                 hue = 'Mode',\n",
    "                 style = 'Method',\n",
    "                 markers = True,\n",
    "                 palette = colorlist,\n",
    "                 color = colorlist,\n",
    "                 markersize = 10,\n",
    "                 dashes = None,\n",
    "                 ci = None,\n",
    "                 ax = ax)\n",
    "    \n",
    "    unique_dfs = [(\"Original\",\"Original\"),\n",
    "                  (\"1\",\"Under\"), (\"1\",\"Over\"),\n",
    "                  (\"2\",\"Under\"),(\"2\",\"Over\"),\n",
    "                  (\"3\",\"Under\"),(\"3\",\"Over\"),\n",
    "                  (\"4\",\"Under\"),(\"4\",\"Over\"),\n",
    "                  (\"5\",\"Under\"),(\"5\",\"Over\"),\n",
    "                  (\"6\",\"Under\"),(\"6\",\"Over\")]\n",
    "    \n",
    "    \n",
    "    for i in range(len(unique_dfs)):\n",
    "        tmp_df = comp_df.loc[(comp_df['Method'] == unique_dfs[i][0]) & (comp_df['Mode']==unique_dfs[i][1]), ].copy()\n",
    "        \n",
    "        x_coords = list(tmp_df.groupby(['Method', 'Mode'])[['value', 'recall_disp']].mean().reset_index()['value'].values)\n",
    "        y_coords = list(tmp_df.groupby(['Method', 'Mode'])[['value', 'recall_disp']].mean().reset_index()['recall_disp'].values)\n",
    "        \n",
    "        \n",
    "        prec_errors = 1.96*tmp_df.groupby(['Method', 'Mode'])['value'].sem().values\n",
    "        disp_errors = 1.96*tmp_df.groupby(['Method', 'Mode'])['recall_disp'].sem().values\n",
    "    \n",
    "        mode = unique_dfs[i][1]\n",
    "        if mode == \"Original\":\n",
    "            color = colorlist[0]\n",
    "        elif mode == \"Under\":\n",
    "            color = colorlist[1]\n",
    "        else:\n",
    "            color = colorlist[2]\n",
    "            \n",
    "        ax.errorbar(x_coords, y_coords,\n",
    "                   xerr = prec_errors,\n",
    "                   yerr = disp_errors,\n",
    "                   ecolor = color, fmt= ' ', zorder=-1, capsize=5)\n",
    "        \n",
    "    ax.set_ylabel('Recall Disparity', fontsize=32)\n",
    "    ax.set_xlabel('Precision at Top-K', fontsize=28)\n",
    "    ax.plot([0.0,1.0],[1.0, 1.0], linestyle = '--', color='black')\n",
    "    \n",
    "    ax.tick_params(axis='x', labelsize=24)\n",
    "    ax.tick_params(axis='y', labelsize=24)\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    hhandles = []\n",
    "    llabels = []\n",
    "\n",
    "    #for i, lab in enumerate(labels):\n",
    "    #    if lab not in list(unique_dfs):\n",
    "    #        handles[i].set_linestyle(\"\")\n",
    "    #        lab = \"Methods\"\n",
    "    #    hhandles.append(handles[i])\n",
    "    #    llabels.append(lab)\n",
    "\n",
    "    ax.legend(handles, labels, fontsize=18, \n",
    "              bbox_to_anchor=(0.015, 0.975), \n",
    "              loc='upper left', \n",
    "              borderaxespad=0., markerscale=2, ncol=1)\n",
    "    \n",
    "    ax.plot([0.1, 0.9], [1.0, 1.0], color='black', linestyle='--')\n",
    "    ax.set_xlim([0.47, 0.58])\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_six(fig_six_df)\n",
    "plt.savefig('../../PLOTS2/PLOTS_Sampling/Joco_Sampling.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_seven_df = pd.concat([filtered_orig_df, filtered_adjusted_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure_seven(comp_df):\n",
    "    colorlist = sns.color_palette(\"dark\", 12).as_hex()\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    data = comp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reindex([\"Original\", \"Post-hoc Adjustment\"]\n",
    "                                                                                ).reset_index()\n",
    "\n",
    "    colorlist = ['#001c7f', #Original\n",
    "                '#a23582']\n",
    "\n",
    "    sns.lineplot(data = data,\n",
    "                 x='value', y='recall_disp',\n",
    "                 hue = 'dataset',\n",
    "                 markers = True,\n",
    "                 palette = colorlist,\n",
    "                 marker = \"o\",\n",
    "                 markersize = 10,\n",
    "                 dashes = None,\n",
    "                 ci = None,\n",
    "                 ax = ax)\n",
    "    \n",
    "    unique_dfs = [\"Original\", \"Post-hoc Adjustment\"]\n",
    "    \n",
    "    for i in range(len(unique_dfs)):\n",
    "        tmp_df = comp_df.loc[comp_df['dataset'] == unique_dfs[i], ].copy()\n",
    "        \n",
    "        x_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['value'].values)\n",
    "        y_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['recall_disp'].values)\n",
    "        \n",
    "        prec_errors = 1.96*tmp_df.groupby(['dataset'])['value'].sem().values\n",
    "        disp_errors = 1.96*tmp_df.groupby(['dataset'])['recall_disp'].sem().values\n",
    "        \n",
    "        color = colorlist[i]\n",
    "        \n",
    "        ax.errorbar(x_coords, y_coords,\n",
    "                   xerr = prec_errors,\n",
    "                   yerr = disp_errors,\n",
    "                   ecolor = colorlist[i], fmt= ' ', zorder=-1, capsize=5)\n",
    "        \n",
    "    ax.set_ylabel('Recall Disparity', fontsize=32)\n",
    "    ax.set_xlabel('Precision at Top-K', fontsize=28)\n",
    "    ax.plot([0.0,1.0],[1.0, 1.0], linestyle = '--', color='black')\n",
    "    \n",
    "    ax.tick_params(axis='x', labelsize=24)\n",
    "    ax.tick_params(axis='y', labelsize=24)\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    hhandles = []\n",
    "    llabels = []\n",
    "\n",
    "    for i, lab in enumerate(labels):\n",
    "        #if lab not in list(unique_dfs):# + ['dataset']:\n",
    "        #    handles[i].set_linestyle(\"\")\n",
    "        if lab not in list(unique_dfs):\n",
    "            handles[i].set_linestyle(\"\")\n",
    "            lab = \"Methods\"\n",
    "        hhandles.append(handles[i])\n",
    "        llabels.append(lab)\n",
    "\n",
    "    llabels = ['Methods', 'Original', 'Post-hoc\\nAdjustment']\n",
    "    ax.legend(hhandles[1:], llabels[1:], fontsize=20, \n",
    "              bbox_to_anchor=(0.01, 0.985), \n",
    "              loc='upper left', \n",
    "              borderaxespad=0., markerscale=2, ncol=1)\n",
    "    \n",
    "    ax.set_ylim([0.9, 1.65])\n",
    "    ax.set_xlim([0.53, 0.58])\n",
    "    ax.plot([0.1, 0.9], [1.0, 1.0], color='black', linestyle='--')\n",
    "    #ax.legend().remove()\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_seven(fig_seven_df)\n",
    "plt.savefig('../../PLOTS2/PLOTS_Post/joco_post.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
