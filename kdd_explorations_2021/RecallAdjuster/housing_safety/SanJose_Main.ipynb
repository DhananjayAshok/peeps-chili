{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display \n",
    "pd.options.display.max_columns = None\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "from jinja2 import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../config/san_jose_db.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-678deea2201b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtriage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../../config/san_jose_db.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mDB_CONFIG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../config/san_jose_db.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from triage import create_engine\n",
    "\n",
    "with open('../../../config/san_jose_db.json') as f:\n",
    "    DB_CONFIG = json.load(f)\n",
    "\n",
    "conn = create_engine(\n",
    "    f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['pass']}@{DB_CONFIG['host']}/{DB_CONFIG['db']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '../../../config/san_jose_db.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-530f037db85e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../../config/san_jose_db.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '../../../config/san_jose_db.yaml'"
     ]
    }
   ],
   "source": [
    "import RecallAdjuster as ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = \"\"\"\n",
    "SELECT DISTINCT model_group_id\n",
    "FROM triage_metadata.model_groups\n",
    "WHERE \n",
    "    model_group_id IN (61, 95, 106, 112, 115, 118)\n",
    "    OR (\n",
    "        model_type ILIKE '%%DecisionTree%%'\n",
    "        AND (\n",
    "            (hyperparameters->'max_depth')::INT < 20\n",
    "            OR\n",
    "            (hyperparameters->'min_samples_split')::INT < 50\n",
    "        )\n",
    "    )\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "exclude_mgs = list(pd.read_sql(sel, conn)['model_group_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "base = datetime.datetime.strptime('2016-06-01', '%Y-%m-%d')\n",
    "date_pairs = []\n",
    "for x in range(17,-1,-1):\n",
    "    date_pairs.append(\n",
    "        (\n",
    "        (base - relativedelta(months=3*x) - relativedelta(years=1)).strftime('%Y-%m-%d'),\n",
    "        (base - relativedelta(months=3*x) - relativedelta(years=1)).strftime('%Y-%m-%d')\n",
    "        )\n",
    "    )\n",
    "    date_pairs.append(\n",
    "        (\n",
    "        (base - relativedelta(months=3*x) - relativedelta(years=1)).strftime('%Y-%m-%d'),\n",
    "        (base - relativedelta(months=3*x)).strftime('%Y-%m-%d')\n",
    "        )\n",
    "    )\n",
    "print(date_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ORIGINAL\n",
    "\n",
    "conn.dispose()\n",
    "conn = create_engine(\n",
    "    f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['pass']}@{DB_CONFIG['host']}/{DB_CONFIG['db']}\"\n",
    ")\n",
    "\n",
    "myRA = ra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='postgres',\n",
    "        schema='hemank_bias_orig',\n",
    "        #experiment_hashes=['357e3a5bc7d3d7cfc2c13db8ea428413', 'a9bf255077d0f97c160e06761c01c637'],\n",
    "        experiment_hashes=['9dcafc4760c3618bfae96a54a4359481'],\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500, 750, 1000],\n",
    "        #entity_demos='joco',\n",
    "        entity_demos='kit_bias_adj.entity_demos',\n",
    "        demo_col='median_income',\n",
    "        exclude_model_groups=exclude_mgs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Under_1_Orig_Orig\n",
    "\n",
    "conn.dispose()\n",
    "conn = create_engine(\n",
    "    f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['pass']}@{DB_CONFIG['host']}/{DB_CONFIG['db']}\"\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "myRA = ra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='postgres',\n",
    "        schema='hemank_bias_under_1_orig_orig',\n",
    "        experiment_hashes=['9f92636ac9a7a4f304e5d0136685bb53'],\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500, 750, 1000],\n",
    "        #entity_demos='joco',\n",
    "        entity_demos='kit_bias_adj.entity_demos',\n",
    "        demo_col='median_income',\n",
    "        exclude_model_groups=exclude_mgs\n",
    ")\n",
    "print(\"Time Taken:\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Under_Original_50_50\n",
    "conn.dispose()\n",
    "conn = create_engine(\n",
    "    f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['pass']}@{DB_CONFIG['host']}/{DB_CONFIG['db']}\"\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "myRA = ra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='postgres',\n",
    "        schema='hemank_bias_under_original_50_50',\n",
    "        experiment_hashes=['29c096cd906beed7472fe1b6911cc724'],\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500, 750, 1000],\n",
    "        #entity_demos='joco',\n",
    "        entity_demos='kit_bias_adj.entity_demos',\n",
    "        demo_col='median_income',\n",
    "        exclude_model_groups=exclude_mgs\n",
    ")\n",
    "print(\"Time Taken:\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under_Original_50_Original\n",
    "conn.dispose()\n",
    "conn = create_engine(\n",
    "    f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['pass']}@{DB_CONFIG['host']}/{DB_CONFIG['db']}\"\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "myRA = ra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='postgres',\n",
    "        schema='hemank_bias_under_original_50_original',\n",
    "        experiment_hashes=['4f795e0f95cc22802a53cb08b63583b9'],\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500, 750, 1000],\n",
    "        #entity_demos='joco',\n",
    "        entity_demos='kit_bias_adj.entity_demos',\n",
    "        demo_col='median_income',\n",
    "        exclude_model_groups=exclude_mgs\n",
    ")\n",
    "print(\"Time Taken:\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under_Original_SNOP_Original\n",
    "conn.dispose()\n",
    "conn = create_engine(\n",
    "    f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['pass']}@{DB_CONFIG['host']}/{DB_CONFIG['db']}\"\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "myRA = ra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='postgres',\n",
    "        schema='hemank_bias_under_original_snop_original',\n",
    "        experiment_hashes=['cb18c1495c73b86eb21525d77733ba54'],\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500, 750, 1000],\n",
    "        #entity_demos='joco',\n",
    "        entity_demos='kit_bias_adj.entity_demos',\n",
    "        demo_col='median_income',\n",
    "        exclude_model_groups=exclude_mgs\n",
    ")\n",
    "print(\"Time Taken:\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under_1_50_50\n",
    "conn.dispose()\n",
    "conn = create_engine(\n",
    "    f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['pass']}@{DB_CONFIG['host']}/{DB_CONFIG['db']}\"\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "myRA = ra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='postgres',\n",
    "        schema='hemank_bias_under_1_50_50',\n",
    "        experiment_hashes=['6ee9df9a2bb685f9b8b03a5b3f9dff9b'],\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500, 750, 1000],\n",
    "        #entity_demos='joco',\n",
    "        entity_demos='kit_bias_adj.entity_demos',\n",
    "        demo_col='median_income',\n",
    "        exclude_model_groups=exclude_mgs\n",
    ")\n",
    "print(\"Time Taken:\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under_1_SNOP_Original\n",
    "conn.dispose()\n",
    "conn = create_engine(\n",
    "    f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['pass']}@{DB_CONFIG['host']}/{DB_CONFIG['db']}\"\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "myRA = ra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='postgres',\n",
    "        schema='hemank_bias_under_1_snop_original',\n",
    "        experiment_hashes=['87587166acf529fb6414fbb68babe013'],\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500, 750, 1000],\n",
    "        #entity_demos='joco',\n",
    "        entity_demos='kit_bias_adj.entity_demos',\n",
    "        demo_col='median_income',\n",
    "        exclude_model_groups=exclude_mgs\n",
    ")\n",
    "print(\"Time Taken:\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over_1_Original_Original\n",
    "conn.dispose()\n",
    "conn = create_engine(\n",
    "    f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['pass']}@{DB_CONFIG['host']}/{DB_CONFIG['db']}\"\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "myRA = ra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='postgres',\n",
    "        schema='hemank_bias_over_1_original_original',\n",
    "        experiment_hashes=['0770d25f5f6736bc6f354a51bfcd088f'],\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500, 750, 1000],\n",
    "        #entity_demos='joco',\n",
    "        entity_demos='kit_bias_adj.entity_demos',\n",
    "        demo_col='median_income',\n",
    "        exclude_model_groups=exclude_mgs\n",
    ")\n",
    "print(\"Time Taken:\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over_original_50_50\n",
    "conn.dispose()\n",
    "conn = create_engine(\n",
    "    f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['pass']}@{DB_CONFIG['host']}/{DB_CONFIG['db']}\"\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "myRA = ra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='postgres',\n",
    "        schema='hemank_bias_over_original_50_50',\n",
    "        experiment_hashes=['754dce4f1806599c151b2073de3c1b5e'],\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500, 750, 1000],\n",
    "        #entity_demos='joco',\n",
    "        entity_demos='kit_bias_adj.entity_demos',\n",
    "        demo_col='median_income',\n",
    "        exclude_model_groups=exclude_mgs\n",
    ")\n",
    "print(\"Time Taken:\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# over_original_50_original\n",
    "conn.dispose()\n",
    "conn = create_engine(\n",
    "    f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['pass']}@{DB_CONFIG['host']}/{DB_CONFIG['db']}\"\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "myRA = ra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='postgres',\n",
    "        schema='hemank_bias_over_original_50_original',\n",
    "        experiment_hashes=['5d196b7f90df16afa9865a620a47342b'],\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500, 750, 1000],\n",
    "        #entity_demos='joco',\n",
    "        entity_demos='kit_bias_adj.entity_demos',\n",
    "        demo_col='median_income',\n",
    "        exclude_model_groups=exclude_mgs\n",
    ")\n",
    "print(\"Time Taken:\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# over_original_snop_original\n",
    "conn.dispose()\n",
    "conn = create_engine(\n",
    "    f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['pass']}@{DB_CONFIG['host']}/{DB_CONFIG['db']}\"\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "myRA = ra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='postgres',\n",
    "        schema='hemank_bias_over_original_snop_original',\n",
    "        experiment_hashes=['cd5cafc29937dc476ac9b71cd0e3b514'],\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500, 750, 1000],\n",
    "        #entity_demos='joco',\n",
    "        entity_demos='kit_bias_adj.entity_demos',\n",
    "        demo_col='median_income',\n",
    "        exclude_model_groups=exclude_mgs\n",
    ")\n",
    "print(\"Time Taken:\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# over_1_50_50\n",
    "conn.dispose()\n",
    "conn = create_engine(\n",
    "    f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['pass']}@{DB_CONFIG['host']}/{DB_CONFIG['db']}\"\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "myRA = ra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='postgres',\n",
    "        schema='hemank_bias_over_1_50_50',\n",
    "        experiment_hashes=['d2d3c40036a5122189f1adee86298a7d'],\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500, 750, 1000],\n",
    "        #entity_demos='joco',\n",
    "        entity_demos='kit_bias_adj.entity_demos',\n",
    "        demo_col='median_income',\n",
    "        exclude_model_groups=exclude_mgs\n",
    ")\n",
    "print(\"Time Taken:\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# over_1_snop_original\n",
    "conn.dispose()\n",
    "conn = create_engine(\n",
    "    f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['pass']}@{DB_CONFIG['host']}/{DB_CONFIG['db']}\"\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "myRA = ra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='postgres',\n",
    "        schema='hemank_bias_over_1_snop_original',\n",
    "        experiment_hashes=['9fd8e8e7591eabb51e17591c82308823'],\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500, 750, 1000],\n",
    "        #entity_demos='joco',\n",
    "        entity_demos='kit_bias_adj.entity_demos',\n",
    "        demo_col='median_income',\n",
    "        exclude_model_groups=exclude_mgs\n",
    ")\n",
    "print(\"Time Taken:\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nop\n",
    "conn.dispose()\n",
    "conn = create_engine(\n",
    "    f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['pass']}@{DB_CONFIG['host']}/{DB_CONFIG['db']}\"\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "myRA = ra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='postgres',\n",
    "        schema='hemank_bias_nop',\n",
    "        experiment_hashes=['7c51c5a62412e88999abefb96c9f55ef'],\n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500, 750, 1000],\n",
    "        #entity_demos='joco',\n",
    "        entity_demos='kit_bias_adj.entity_demos',\n",
    "        demo_col='median_income',\n",
    "        exclude_model_groups=exclude_mgs\n",
    ")\n",
    "print(\"Time Taken:\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoupled\n",
    "\n",
    "conn.dispose()\n",
    "conn = create_engine(\n",
    "    f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['pass']}@{DB_CONFIG['host']}/{DB_CONFIG['db']}\"\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "myRA = ra.RecallAdjuster(\n",
    "        engine=conn,\n",
    "        pg_role='postgres',\n",
    "        schema='hemank_bias_decoupled',\n",
    "        experiment_hashes = '',\n",
    "        decoupled_experiments=[('c44b928c3ff18ab72c262c020ddc876e','over55k'),\n",
    "                           ('217ec46d626706211b3682d511e42143','under55k')],\n",
    "    \n",
    "        date_pairs=date_pairs,\n",
    "        list_sizes=[500, 750, 1000],\n",
    "        #entity_demos='joco',\n",
    "        entity_demos='kit_bias_adj.entity_demos',\n",
    "        demo_col='median_income',\n",
    "        exclude_model_groups=exclude_mgs\n",
    ")\n",
    "print(\"Time Taken:\"+str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = Template(\"\"\"\n",
    "WITH mg_rns AS (\n",
    "  SELECT *,\n",
    "         row_number() OVER (PARTITION BY train_end_time, list_size, metric, parameter ORDER BY base_value DESC, base_max_recall_ratio ASC, RANDOM()) AS rn_base,\n",
    "         row_number() OVER (PARTITION BY train_end_time, list_size, metric, parameter ORDER BY adj_value DESC, adj_max_recall_ratio ASC, RANDOM()) AS rn_adj\n",
    "  FROM {{schema}}.model_adjustment_results_median_income\n",
    "  WHERE past_train_end_time = train_end_time\n",
    ")\n",
    ", base_mgs AS (\n",
    "  SELECT * FROM mg_rns WHERE rn_base = 1\n",
    ")\n",
    ", adj_mgs AS (\n",
    "  SELECT * FROM mg_rns WHERE rn_adj = 1\n",
    ")\n",
    "\n",
    "-- Simple model selection on last time period, baseline with no recall adjustments\n",
    "SELECT 'Best Unadjusted Metric - Unadjusted'::VARCHAR(128) AS strategy,\n",
    "       r.train_end_time, r.past_train_end_time,\n",
    "       r.list_size, r.metric, r.parameter,\n",
    "       r.base_value AS value,\n",
    "       r.base_max_recall_ratio AS max_recall_ratio,\n",
    "       r.base_recall_under55k_to_over55k AS recall_under_to_over,\n",
    "       r.base_recall_over55k_to_under55k AS recall_over_to_under\n",
    "FROM {{schema}}.model_adjustment_results_median_income r\n",
    "JOIN base_mgs b\n",
    "  ON r.model_group_id = b.model_group_id\n",
    "  AND r.past_train_end_time = b.train_end_time\n",
    "  AND r.list_size = b.list_size\n",
    "  AND r.metric = b.metric\n",
    "  AND r.parameter = b.parameter\n",
    "WHERE r.train_end_time > r.past_train_end_time\n",
    "AND r.list_size = 500\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "-- Model selection on last time before adjustment, with adjustment applied\n",
    "SELECT 'Best Unadjusted Metric - Adjusted'::VARCHAR(128) AS strategy,\n",
    "       r.train_end_time, r.past_train_end_time,\n",
    "       r.list_size, r.metric, r.parameter,\n",
    "       r.adj_value AS value,\n",
    "       r.adj_max_recall_ratio AS max_recall_ratio,\n",
    "       r.adj_recall_under55k_to_over55k AS recall_under_to_over,\n",
    "       r.adj_recall_over55k_to_under55k AS recall_over_to_under\n",
    "FROM {{schema}}.model_adjustment_results_median_income r\n",
    "JOIN base_mgs b\n",
    "  ON r.model_group_id = b.model_group_id\n",
    "  AND r.past_train_end_time = b.train_end_time\n",
    "  AND r.list_size = b.list_size\n",
    "  AND r.metric = b.metric\n",
    "  AND r.parameter = b.parameter\n",
    "WHERE r.train_end_time > r.past_train_end_time\n",
    "AND r.list_size = 500\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "-- Model selection on last time after adjustment, with adjustment applied\n",
    "SELECT 'Best Adjusted Metric - Adjusted'::VARCHAR(128) AS strategy,\n",
    "       r.train_end_time, r.past_train_end_time,\n",
    "       r.list_size, r.metric, r.parameter,\n",
    "       r.adj_value AS value,\n",
    "       r.adj_max_recall_ratio AS max_recall_ratio,\n",
    "       r.adj_recall_under55k_to_over55k AS recall_under_to_over,\n",
    "       r.adj_recall_over55k_to_under55k AS recall_over_to_under\n",
    "FROM {{schema}}.model_adjustment_results_median_income r\n",
    "JOIN adj_mgs b\n",
    "  ON r.model_group_id = b.model_group_id\n",
    "  AND r.past_train_end_time = b.train_end_time\n",
    "  AND r.list_size = b.list_size\n",
    "  AND r.metric = b.metric\n",
    "  AND r.parameter = b.parameter\n",
    "WHERE r.train_end_time > r.past_train_end_time\n",
    "AND r.list_size = 500\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "-- Composite model\n",
    "SELECT 'Composite Model - Adjusted'::VARCHAR(128) AS strategy,\n",
    "      r.train_end_time AS train_end_time,\n",
    "      r.past_train_end_time AS past_train_end_time,\n",
    "      r.list_size, metric, parameter,\n",
    "      r.value AS value,\n",
    "      r.max_recall_ratio AS max_recall_ratio,\n",
    "      r.recall_under55k_to_over55k AS recall_under_to_over,\n",
    "      r.recall_over55k_to_under55k AS recall_over_to_under\n",
    "FROM {{schema}}.composite_results_median_income r\n",
    "WHERE train_end_time > past_train_end_time\n",
    "AND r.list_size=500\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['schema'] = 'hemank_bias_orig'\n",
    "sql_orig = query.render(**params)\n",
    "ts_df_orig = pd.read_sql(sql_orig, conn)\n",
    "\n",
    "params = {}\n",
    "params['schema'] = 'hemank_bias_nop'\n",
    "sql_nop = query.render(**params)\n",
    "ts_df_nop = pd.read_sql(sql_nop, conn)\n",
    "\n",
    "#params = {}\n",
    "#params['schema'] = 'hemank_bias_decoupled'\n",
    "#sql_dec = query.render(**params)\n",
    "#ts_df_dec = pd.read_sql(sql_dec, conn)\n",
    "\n",
    "params['schema'] = 'hemank_bias_under_1_orig_orig'\n",
    "sql_us = query.render(**params)\n",
    "ts_df_u_v1a = pd.read_sql(sql_us, conn)\n",
    "\n",
    "params['schema'] = 'hemank_bias_under_original_50_50'\n",
    "sql_us = query.render(**params)\n",
    "ts_df_u_v2a = pd.read_sql(sql_us, conn)\n",
    "\n",
    "params['schema'] = 'hemank_bias_under_original_snop_original'\n",
    "sql_us = query.render(**params)\n",
    "ts_df_u_v2b = pd.read_sql(sql_us, conn)\n",
    "\n",
    "params['schema'] = 'hemank_bias_under_original_50_original'\n",
    "sql_us = query.render(**params)\n",
    "ts_df_u_v2c = pd.read_sql(sql_us, conn)\n",
    "\n",
    "params['schema'] = 'hemank_bias_under_1_50_50'\n",
    "sql_us = query.render(**params)\n",
    "ts_df_u_v3a = pd.read_sql(sql_us, conn)\n",
    "\n",
    "params['schema'] = 'hemank_bias_under_1_snop_original'\n",
    "sql_us = query.render(**params)\n",
    "ts_df_u_v3b = pd.read_sql(sql_us, conn)\n",
    "\n",
    "params['schema'] = 'hemank_bias_over_1_original_original'\n",
    "sql_os = query.render(**params)\n",
    "ts_df_o_v1a = pd.read_sql(sql_os, conn)\n",
    "\n",
    "params['schema'] = 'hemank_bias_over_original_50_50'\n",
    "sql_os = query.render(**params)\n",
    "ts_df_o_v2a = pd.read_sql(sql_os, conn)\n",
    "\n",
    "params['schema'] = 'hemank_bias_over_original_snop_original'\n",
    "sql_os = query.render(**params)\n",
    "ts_df_o_v2b = pd.read_sql(sql_os, conn)\n",
    "\n",
    "params['schema'] = 'hemank_bias_over_original_50_original'\n",
    "sql_os = query.render(**params)\n",
    "ts_df_o_v2c = pd.read_sql(sql_os, conn)\n",
    "\n",
    "params['schema'] = 'hemank_bias_over_1_50_50'\n",
    "sql_os = query.render(**params)\n",
    "ts_df_o_v3a = pd.read_sql(sql_os, conn)\n",
    "\n",
    "params['schema'] = 'hemank_bias_over_1_snop_original'\n",
    "sql_os = query.render(**params)\n",
    "ts_df_o_v3b = pd.read_sql(sql_os, conn)\n",
    "\n",
    "params['schema'] = 'hemank_bias_zafar'\n",
    "sql_zafar = query.render(**params)\n",
    "ts_df_zafar = pd.read_sql(sql_zafar, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_decoupled = Template(\"\"\"\n",
    "WITH mg_rns AS (\n",
    "  SELECT *,\n",
    "         row_number() OVER (PARTITION BY train_end_time, list_size, metric, parameter ORDER BY base_value DESC, base_max_recall_ratio ASC, RANDOM()) AS rn_base,\n",
    "         row_number() OVER (PARTITION BY train_end_time, list_size, metric, parameter ORDER BY adj_value DESC, adj_max_recall_ratio ASC, RANDOM()) AS rn_adj\n",
    "  FROM {{schema}}.model_adjustment_results_median_income\n",
    "  WHERE past_train_end_time = train_end_time\n",
    ")\n",
    ", base_mgs AS (\n",
    "  SELECT * FROM mg_rns WHERE rn_base = 1\n",
    ")\n",
    ", adj_mgs AS (\n",
    "  SELECT * FROM mg_rns WHERE rn_adj = 1\n",
    ")\n",
    "\n",
    "\n",
    "-- -- Composite model (with decoupled models)\n",
    "SELECT 'Composite w/ Decoupled - Adjusted'::VARCHAR(128) AS strategy,\n",
    "      train_end_time, past_train_end_time,\n",
    "      list_size, metric, parameter,\n",
    "      value,\n",
    "      max_recall_ratio,\n",
    "      recall_under55k_to_over55k AS recall_under_to_over,\n",
    "      recall_over55k_to_under55k AS recall_over_to_under\n",
    "FROM {{schema}}.composite_results_decoupled_median_income\n",
    "WHERE train_end_time > past_train_end_time\n",
    ";\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['schema'] = 'hemank_bias_decoupled'\n",
    "sql_dec = sql_decoupled.render(**params)\n",
    "ts_df_dec = pd.read_sql(sql_dec, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df_orig['dataset'] = 'Original'\n",
    "orig_df = ts_df_orig.rename(\n",
    "    {'recall_over_to_under': 'recall_disp'\n",
    "    }, axis='columns')\n",
    "orig_df = orig_df.loc[orig_df['train_end_time'] >= '2014-06-01', ]\n",
    "\n",
    "ts_df_nop['dataset'] = 'NoP'\n",
    "nop_df = ts_df_nop.rename(\n",
    "    {'recall_over_to_under': 'recall_disp'\n",
    "    }, axis='columns')\n",
    "nop_df = nop_df.loc[nop_df['train_end_time'] >= '2014-06-01', ]\n",
    "\n",
    "ts_df_dec['dataset'] = 'DeCoupled'\n",
    "dec_df = ts_df_dec.rename(\n",
    "    {'recall_over_to_under': 'recall_disp'\n",
    "    }, axis='columns')\n",
    "dec_df = dec_df.loc[dec_df['train_end_time'] >= '2014-06-01']\n",
    "\n",
    "ts_df_zafar['dataset'] = 'Zafar'\n",
    "zafar_df = ts_df_zafar.rename(\n",
    "    {'recall_over_to_under': 'recall_disp'\n",
    "    }, axis='columns')\n",
    "zafar_df = zafar_df.loc[zafar_df['train_end_time'] >= '2014-06-01']\n",
    "\n",
    "ts_df_u_v1a['dataset'] = 'Under-v1a'\n",
    "u_v1a_df = ts_df_u_v1a.rename(\n",
    "    {'recall_over_to_under': 'recall_disp'\n",
    "    }, axis='columns')\n",
    "u_v1a_df = u_v1a_df.loc[u_v1a_df['train_end_time'] >= '2014-06-01', ]\n",
    "\n",
    "ts_df_u_v2a['dataset'] = 'Under-v2a'\n",
    "u_v2a_df = ts_df_u_v2a.rename(\n",
    "    {'recall_over_to_under': 'recall_disp'\n",
    "    }, axis='columns')\n",
    "u_v2a_df = u_v2a_df.loc[u_v2a_df['train_end_time'] >= '2014-06-01', ]\n",
    "\n",
    "ts_df_u_v2b['dataset'] = 'Under-v2b'\n",
    "u_v2b_df = ts_df_u_v2b.rename(\n",
    "    {'recall_over_to_under': 'recall_disp'\n",
    "    }, axis='columns')\n",
    "u_v2b_df = u_v2b_df.loc[u_v2b_df['train_end_time'] >= '2014-06-01', ]\n",
    "\n",
    "ts_df_u_v2c['dataset'] = 'Under-v2c'\n",
    "u_v2c_df = ts_df_u_v2c.rename(\n",
    "    {'recall_over_to_under': 'recall_disp'\n",
    "    }, axis='columns')\n",
    "u_v2c_df = u_v2c_df.loc[u_v2c_df['train_end_time'] >= '2014-06-01', ]\n",
    "\n",
    "ts_df_u_v3a['dataset'] = 'Under-v3a'\n",
    "u_v3a_df = ts_df_u_v3a.rename(\n",
    "    {'recall_over_to_under': 'recall_disp'\n",
    "    }, axis='columns')\n",
    "u_v3a_df = u_v3a_df.loc[u_v3a_df['train_end_time'] >= '2014-06-01', ]\n",
    "\n",
    "\n",
    "ts_df_u_v3b['dataset'] = 'Under-v3b'\n",
    "u_v3b_df = ts_df_u_v3b.rename(\n",
    "    {'recall_over_to_under': 'recall_disp'\n",
    "    }, axis='columns')\n",
    "u_v3b_df = u_v3b_df.loc[u_v3b_df['train_end_time'] >= '2014-06-01', ]\n",
    "\n",
    "\n",
    "ts_df_o_v1a['dataset'] = 'Over-v1a'\n",
    "o_v1a_df = ts_df_o_v1a.rename(\n",
    "    {'recall_over_to_under': 'recall_disp'\n",
    "    }, axis='columns')\n",
    "o_v1a_df = o_v1a_df.loc[o_v1a_df['train_end_time'] >= '2014-06-01', ]\n",
    "\n",
    "ts_df_o_v2a['dataset'] = 'Over-v2a'\n",
    "o_v2a_df = ts_df_o_v2a.rename(\n",
    "    {'recall_over_to_under': 'recall_disp'\n",
    "    }, axis='columns')\n",
    "o_v2a_df = o_v2a_df.loc[o_v2a_df['train_end_time'] >= '2014-06-01', ]\n",
    "\n",
    "ts_df_o_v2b['dataset'] = 'Over-v2b'\n",
    "o_v2b_df = ts_df_o_v2b.rename(\n",
    "    {'recall_over_to_under': 'recall_disp'\n",
    "    }, axis='columns')\n",
    "o_v2b_df = o_v2b_df.loc[o_v2b_df['train_end_time'] >= '2014-06-01', ]\n",
    "\n",
    "ts_df_o_v2c['dataset'] = 'Over-v2c'\n",
    "o_v2c_df = ts_df_o_v2c.rename(\n",
    "    {'recall_over_to_under': 'recall_disp'\n",
    "    }, axis='columns')\n",
    "o_v2c_df = o_v2c_df.loc[o_v2c_df['train_end_time'] >= '2014-06-01', ]\n",
    "\n",
    "ts_df_o_v3a['dataset'] = 'Over-v3a'\n",
    "o_v3a_df = ts_df_o_v3a.rename(\n",
    "    {'recall_over_to_under': 'recall_disp'\n",
    "    }, axis='columns')\n",
    "o_v3a_df = o_v3a_df.loc[o_v3a_df['train_end_time'] >= '2014-06-01', ]\n",
    "\n",
    "ts_df_o_v3b['dataset'] = 'Over-v3b'\n",
    "o_v3b_df = ts_df_o_v3b.rename(\n",
    "    {'recall_over_to_under': 'recall_disp'\n",
    "    }, axis='columns')\n",
    "o_v3b_df = o_v3b_df.loc[o_v3b_df['train_end_time'] >= '2014-06-01', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([orig_df, nop_df, zafar_df, dec_df])\n",
    "under_df = pd.concat([orig_df, u_v1a_df, u_v2a_df, u_v2b_df, u_v2c_df, u_v3a_df, u_v3b_df])\n",
    "over_df = pd.concat([orig_df, o_v1a_df, o_v2a_df, o_v2b_df, o_v2c_df, o_v3a_df, o_v3b_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig_two_df = pd.concat([orig_df, nop_df, zafar_df, decoupled_df])\n",
    "\n",
    "filtered_original_df = orig_df[(orig_df['strategy'] == 'Best Unadjusted Metric - Unadjusted')]\n",
    "filtered_original_df.loc[:,'dataset'] = 'Original'\n",
    "filtered_original_df.loc[:,'strategy'] = 'No Adjustment'\n",
    "\n",
    "filtered_adjusted_df = orig_df[(orig_df['strategy'] == 'Best Unadjusted Metric - Adjusted')]\n",
    "filtered_adjusted_df.loc[:,'dataset'] = 'Post-hoc Adjustment'\n",
    "filtered_adjusted_df.loc[:,'strategy'] = 'Post-hoc Adjustment'\n",
    "\n",
    "filtered_composite_df = orig_df[(orig_df['strategy'] == 'Composite Model - Adjusted')]\n",
    "filtered_composite_df.loc[:,'dataset'] = 'Composite Adjusted'\n",
    "filtered_composite_df.loc[:,'strategy'] = 'Composite Adjusted'\n",
    "\n",
    "filtered_nop_df = nop_df[nop_df['strategy'] == 'Best Unadjusted Metric - Unadjusted']\n",
    "filtered_nop_df.loc[:,'dataset'] = 'No Protected'\n",
    "filtered_nop_df.loc[:,'strategy'] = 'No Protected'\n",
    "\n",
    "filtered_zafar_df = zafar_df[zafar_df['strategy'] == 'Best Unadjusted Metric - Unadjusted']\n",
    "filtered_zafar_df.loc[:,'dataset'] = 'Regularization'\n",
    "filtered_zafar_df.loc[:,'strategy'] = 'Regularization'\n",
    "\n",
    "best_prec_df = u_v3b_df[u_v3b_df['strategy'] == 'Best Unadjusted Metric - Unadjusted']\n",
    "best_prec_df.loc[:,'dataset'] = 'Sampling (Best Precision)'\n",
    "best_prec_df.loc[:,'strategy'] = 'Sampling (Best Precision)'\n",
    "\n",
    "best_equity_df = o_v2a_df[o_v2a_df['strategy'] == 'Best Unadjusted Metric - Unadjusted']\n",
    "best_equity_df.loc[:,'dataset'] = 'Sampling (Best Equity)'\n",
    "best_equity_df.loc[:,'strategy'] = 'Sampling (Best Equity)'\n",
    "\n",
    "fig_two_df = pd.concat([filtered_original_df, filtered_nop_df, filtered_zafar_df, \n",
    "                        best_prec_df, best_equity_df, filtered_adjusted_df,\n",
    "                       filtered_composite_df])\n",
    "\n",
    "fig_three_df = pd.concat([filtered_original_df, filtered_nop_df])\n",
    "fig_four_df = pd.concat([filtered_original_df, filtered_zafar_df])\n",
    "\n",
    "decoupled_df = dec_df\n",
    "\n",
    "filtered_decoupled_df = decoupled_df[(decoupled_df['strategy'] == 'Composite w/ Decoupled - Adjusted')]\n",
    "filtered_decoupled_df.loc[:,'strategy'] = 'Decoupled'\n",
    "filtered_decoupled_df.loc[:,'dataset'] = 'Decoupled'\n",
    "\n",
    "fig_five_df = pd.concat([filtered_original_df, filtered_composite_df, filtered_decoupled_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure_two(comp_df):\n",
    "    colorlist = sns.color_palette(\"dark\", 12).as_hex()\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    #data = comp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()\n",
    "    data = comp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reindex([\"Original\", \"No Protected\", \n",
    "                                                                                        \"Sampling (Best Equity)\",\n",
    "                                                                                       \"Sampling (Best Precision)\",\n",
    "                                                                                       \"Composite Adjusted\",\n",
    "                                                                                       \"Regularization\", \n",
    "                                                                                  \"Post-hoc Adjustment\"]).reset_index()\n",
    "\n",
    "    unique_dfs = [\"Original\", \"No Protected\", \"Sampling (Best Equity)\", \"Sampling (Best Precision)\",\n",
    "                 \"Composite Adjusted\", \"Regularization\", \"Post-hoc Adjustment\"]\n",
    "    \n",
    "    colorlist = ['#001c7f', #Original\n",
    "                 '#b1400d', #No_Protected\n",
    "                 '#12711c', #Best Sampling(Equity)\n",
    "                 #'#8c0800', #OLD -Best Sampling(Precision)\n",
    "                 '#7CFC00', #NEW - Best Sampling(Precision)\n",
    "                 '#591e71', #Composite Adjustment\n",
    "                 '#592f0d', #Regularization\n",
    "                 '#a23582' #Post-hoc Adjustment\n",
    "                ]\n",
    "\n",
    "    \n",
    "    sns.lineplot(data = data,\n",
    "                 x='value', y='recall_disp',\n",
    "                 hue = 'dataset',\n",
    "                 markers = True,\n",
    "                 palette = colorlist,\n",
    "                 linewidth = 20.0,\n",
    "                 marker = \"o\",\n",
    "                 markersize = 10,\n",
    "                 dashes = None,\n",
    "                 ci = None,\n",
    "                 ax = ax)\n",
    "    \n",
    "    #unique_dfs = np.unique(data['dataset'])\n",
    "    \n",
    "    for i in range(len(unique_dfs)):\n",
    "        tmp_df = comp_df.loc[comp_df['dataset'] == unique_dfs[i], ].copy()\n",
    "        \n",
    "        x_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['value'].values)\n",
    "        y_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['recall_disp'].values)\n",
    "        \n",
    "        prec_errors = 1.96*tmp_df.groupby(['dataset'])['value'].sem().values\n",
    "        disp_errors = 1.96*tmp_df.groupby(['dataset'])['recall_disp'].sem().values\n",
    "        \n",
    "        color = colorlist[i]\n",
    "        \n",
    "        ax.errorbar(x_coords, y_coords,\n",
    "                   xerr = prec_errors,\n",
    "                   yerr = disp_errors,\n",
    "                   ecolor = colorlist[i], fmt= ' ', zorder=-1, capsize=5, linewidth=3.0)\n",
    "        \n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('Precision at Top-K', fontsize=28)\n",
    "    ax.plot([0.0, 1.0], [1.0, 1.0], linestyle='--', color='black')\n",
    "    ax.tick_params(axis='x', labelsize=22)\n",
    "    ax.tick_params(axis='y', labelsize=24)\n",
    "    #ax.get_legend().remove()\n",
    "    ax.plot([0.0,1.0], [1.0, 1.0], color='black', linestyle='--')\n",
    "    ax.set_xlim([0.75,0.82])\n",
    "    ax.legend().remove()\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_two(fig_two_df)\n",
    "plt.savefig('../../PLOTS2/PLOTS_Summary/SanJose_Methods_NEW.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure_three(comp_df):\n",
    "    colorlist = sns.color_palette(\"dark\", 12).as_hex()\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    data = comp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reindex([\"Original\", \"No Protected\"]\n",
    "                                                                                ).reset_index()\n",
    "    colorlist = ['#001c7f', #Original\n",
    "                 '#b1400d']\n",
    "    unique_dfs = [\"Original\", \"No Protected\"]\n",
    "    \n",
    "    sns.lineplot(data = data,\n",
    "                 x='value', y='recall_disp',\n",
    "                 hue = 'dataset',\n",
    "                 markers = True,\n",
    "                 palette = colorlist,\n",
    "                 marker = \"o\",\n",
    "                 markersize = 10,\n",
    "                 dashes = None,\n",
    "                 ci = None,\n",
    "                 ax = ax)\n",
    "    \n",
    "    unique_dfs = [\"Original\", \"No Protected\"]\n",
    "        \n",
    "    for i in range(len(unique_dfs)):\n",
    "        tmp_df = comp_df.loc[comp_df['dataset'] == unique_dfs[i], ].copy()\n",
    "        \n",
    "        x_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['value'].values)\n",
    "        y_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['recall_disp'].values)\n",
    "        \n",
    "        prec_errors = 1.96*tmp_df.groupby(['dataset'])['value'].sem().values\n",
    "        disp_errors = 1.96*tmp_df.groupby(['dataset'])['recall_disp'].sem().values\n",
    "        \n",
    "        color = colorlist[i]\n",
    "        \n",
    "        ax.errorbar(x_coords, y_coords,\n",
    "                   xerr = prec_errors,\n",
    "                   yerr = disp_errors,\n",
    "                   ecolor = colorlist[i], fmt= ' ', zorder=-1, capsize=5, linewidth=3.0)\n",
    "        \n",
    "        \n",
    "    ax.set_ylabel('', fontsize=32)\n",
    "    ax.set_xlabel('Precision at Top-K', fontsize=28)\n",
    "    ax.plot([0.0,1.0],[1.0, 1.0], linestyle = '--', color='black')\n",
    "    \n",
    "    ax.tick_params(axis='x', labelsize=24)\n",
    "    ax.tick_params(axis='y', labelsize=24)\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    hhandles = []\n",
    "    llabels = []\n",
    "\n",
    "    for i, lab in enumerate(labels):\n",
    "        #if lab not in list(unique_dfs):# + ['dataset']:\n",
    "        #    handles[i].set_linestyle(\"\")\n",
    "        if lab not in list(unique_dfs):\n",
    "            handles[i].set_linestyle(\"\")\n",
    "            lab = \"Methods\"\n",
    "        hhandles.append(handles[i])\n",
    "        llabels.append(lab)\n",
    "\n",
    "    ax.legend(hhandles[1:], llabels[1:], fontsize=24, \n",
    "              bbox_to_anchor=(0.025, 0.125), \n",
    "              loc='lower left', \n",
    "              borderaxespad=0., markerscale=2, ncol=1)\n",
    "    \n",
    "    ax.set_ylim([0.9, 2.0])\n",
    "    ax.set_xlim([0.75, 0.81])\n",
    "    ax.plot([0.0, 1.0], [1.0, 1.0], color='black', linestyle='--')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_three(fig_three_df)\n",
    "plt.savefig('../../PLOTS2/PLOTS_NOP/NoP_SanJose.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure_four(comp_df):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    data = comp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reindex([\"Original\", \"Regularization\"]\n",
    "                                                                                ).reset_index()\n",
    "    colorlist = ['#001c7f', '#592f0d'] #Regularization\n",
    "    \n",
    "    unique_dfs = [\"Original\", \"Regularization\"]\n",
    "\n",
    "    sns.lineplot(data = data,\n",
    "                 x='value', y='recall_disp',\n",
    "                 hue = 'dataset',\n",
    "                 markers = True,\n",
    "                 palette = colorlist,\n",
    "                 linewidth = 20.0,\n",
    "                 marker = \"o\",\n",
    "                 markersize = 10,\n",
    "                 dashes = None,\n",
    "                 ci = None,\n",
    "                 ax = ax)\n",
    "    \n",
    "    for i in range(len(unique_dfs)):\n",
    "        tmp_df = comp_df.loc[comp_df['dataset'] == unique_dfs[i], ].copy()        \n",
    "        x_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['value'].values)\n",
    "        y_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['recall_disp'].values)\n",
    "        \n",
    "        prec_errors = 1.96*tmp_df.groupby(['dataset'])['value'].sem().values\n",
    "        disp_errors = 1.96*tmp_df.groupby(['dataset'])['recall_disp'].sem().values\n",
    "        \n",
    "        color = colorlist[i]\n",
    "    \n",
    "        ax.errorbar(x_coords, y_coords,\n",
    "                   xerr = prec_errors,\n",
    "                   yerr = disp_errors,\n",
    "                   ecolor = colorlist[i], fmt= ' ', zorder=-1, capsize=5, linewidth=3.0)\n",
    "        \n",
    "    ax.set_ylabel('', fontsize=32)\n",
    "    ax.set_xlabel('Precision at Top-K', fontsize=28)\n",
    "    ax.plot([0.0,1.0],[1.0, 1.0], linestyle = '--', color='black')\n",
    "    \n",
    "    ax.tick_params(axis='x', labelsize=24)\n",
    "    ax.tick_params(axis='y', labelsize=24)\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    hhandles = []\n",
    "    llabels = []\n",
    "\n",
    "    for i, lab in enumerate(labels):\n",
    "        #if lab not in list(unique_dfs):# + ['dataset']:\n",
    "        #    handles[i].set_linestyle(\"\")\n",
    "        if lab not in list(unique_dfs):\n",
    "            handles[i].set_linestyle(\"\")\n",
    "            lab = \"Methods\"\n",
    "        hhandles.append(handles[i])\n",
    "        llabels.append(lab)\n",
    "\n",
    "    ax.legend(hhandles[1:], llabels[1:], fontsize=24, \n",
    "              bbox_to_anchor=(0.0125, 0.125), \n",
    "              loc='lower left', \n",
    "              borderaxespad=0., markerscale=2, ncol=1)\n",
    "    \n",
    "    ax.set_ylim([0.88, 2.1])\n",
    "    ax.set_xlim([0.74, 0.82])\n",
    "    ax.plot([0.0, 1.0], [1.0, 1.0], color='black', linestyle='--')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_four(fig_four_df)\n",
    "plt.savefig('../../PLOTS2/PLOTS_Zafar/sanjose_zafar.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure_five(comp_df):\n",
    "    colorlist = sns.color_palette(\"dark\", 12).as_hex()\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    data = comp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reindex([\"Original\", \"Composite Adjusted\", \"Decoupled\"]\n",
    "                                                                                ).reset_index()\n",
    "\n",
    "    colorlist = ['#001c7f', #Original\n",
    "                 '#591e71', # Composite Adjustment\n",
    "                 '#3c3c3c' # Decoupled\n",
    "                ]\n",
    "\n",
    "    sns.lineplot(data = data,\n",
    "                 x='value', y='recall_disp',\n",
    "                 hue = 'dataset',\n",
    "                 markers = True,\n",
    "                 palette = colorlist,\n",
    "                 marker = \"o\",\n",
    "                 markersize = 10,\n",
    "                 dashes = None,\n",
    "                 ci = None,\n",
    "                 ax = ax)\n",
    "    \n",
    "    unique_dfs = [\"Original\", \"Composite Adjusted\", \"Decoupled\"]\n",
    "    \n",
    "    for i in range(len(unique_dfs)):\n",
    "        tmp_df = comp_df.loc[comp_df['dataset'] == unique_dfs[i], ].copy()\n",
    "        \n",
    "        x_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['value'].values)\n",
    "        y_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['recall_disp'].values)\n",
    "        \n",
    "        prec_errors = 1.96*tmp_df.groupby(['dataset'])['value'].sem().values\n",
    "        disp_errors = 1.96*tmp_df.groupby(['dataset'])['recall_disp'].sem().values\n",
    "        \n",
    "        color = colorlist[i]\n",
    "        \n",
    "        ax.errorbar(x_coords, y_coords,\n",
    "                   xerr = prec_errors,\n",
    "                   yerr = disp_errors,\n",
    "                   ecolor = colorlist[i], fmt= ' ', zorder=-1, capsize=5)\n",
    "        \n",
    "    ax.set_ylabel('Recall Disparity', fontsize=32)\n",
    "    ax.set_xlabel('Precision at Top-K', fontsize=28)\n",
    "    ax.plot([0.0,1.0],[1.0, 1.0], linestyle = '--', color='black')\n",
    "    \n",
    "    ax.tick_params(axis='x', labelsize=24)\n",
    "    ax.tick_params(axis='y', labelsize=24)\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    hhandles = []\n",
    "    llabels = []\n",
    "\n",
    "    for i, lab in enumerate(labels):\n",
    "        #if lab not in list(unique_dfs):# + ['dataset']:\n",
    "        #    handles[i].set_linestyle(\"\")\n",
    "        if lab not in list(unique_dfs):\n",
    "            handles[i].set_linestyle(\"\")\n",
    "            lab = \"Methods\"\n",
    "        hhandles.append(handles[i])\n",
    "        llabels.append(lab)\n",
    "\n",
    "    ax.legend(hhandles[1:], llabels[1:], fontsize=20, \n",
    "              bbox_to_anchor=(0.015, 0.975), \n",
    "              loc='upper left', \n",
    "              borderaxespad=0., markerscale=2, ncol=1)    \n",
    "    ax.set_ylim([0.6, 2.1])\n",
    "    ax.set_xlim([0.7, 0.82])\n",
    "    ax.plot([0.0, 1.0], [1.0, 1.0], color='black', linestyle='--')\n",
    "    #ax.legend().remove()\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_five(fig_five_df)\n",
    "plt.savefig('../../PLOTS2/PLOTS_Composite/Composite_SanJose.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode(x):\n",
    "    if \"Original\" in x:\n",
    "        return \"Original\"\n",
    "    elif \"U\" in x:\n",
    "        return \"Under\"\n",
    "    return \"Over\"\n",
    "\n",
    "usamp_df = pd.concat([u_v1a_df, u_v2a_df, u_v2b_df, u_v2c_df, u_v3a_df, u_v3b_df])\n",
    "osamp_df = pd.concat([o_v1a_df, o_v2a_df, o_v2b_df, o_v2c_df, o_v3a_df, o_v3b_df])\n",
    "\n",
    "filtered_orig_df = orig_df[(orig_df['strategy'] == 'Best Unadjusted Metric - Unadjusted')]\n",
    "filtered_usamp_df = usamp_df[(usamp_df['strategy'] == 'Best Unadjusted Metric - Unadjusted')]\n",
    "filtered_osamp_df = osamp_df[(osamp_df['strategy'] == 'Best Unadjusted Metric - Unadjusted')]\n",
    "\n",
    "fig_six_df = pd.concat([filtered_orig_df, filtered_usamp_df, filtered_osamp_df])\n",
    "fig_six_df.loc[fig_six_df['strategy']=='Best Unadjusted Metric - Unadjusted', 'strategy'] = 'No Adjustment'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Original', 'mode'] = 'Original'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v1a', 'mode'] = 'Under'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v1a', 'dataset'] = '1'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v2a', 'mode'] = 'Under'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v2a', 'dataset'] = '2'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v2b', 'mode'] = 'Under'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v2b', 'dataset'] = '3'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v2c', 'mode'] = 'Under'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v2c', 'dataset'] = '4'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v3a', 'mode'] = 'Under'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v3a', 'dataset'] = '5'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v3b', 'mode'] = 'Under'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v3b', 'dataset'] = '6'\n",
    "\n",
    "fig_six_df.loc[fig_six_df['strategy']=='Best Unadjusted Metric - Unadjusted', 'strategy'] = 'No Adjustment'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v1a', 'mode'] = 'Over'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v1a', 'dataset'] = '1'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v2a', 'mode'] = 'Over'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v2a', 'dataset'] = '2'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v2b', 'mode'] = 'Over'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v2b', 'dataset'] = '3'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v2c', 'mode'] = 'Over'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v2c', 'dataset'] = '4'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v3a', 'mode'] = 'Over'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v3a', 'dataset'] = '5'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v3b', 'mode'] = 'Over'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v3b', 'dataset'] = '6'\n",
    "\n",
    "fig_six_df = fig_six_df.rename(columns={\"dataset\": \"Method\", \"mode\":\"Mode\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_six_df.groupby(['Method', 'Mode'])[['value', 'recall_disp']].mean().reindex([\n",
    "        (\"Original\", \"Original\"),\n",
    "        (\"1\", \"Under\"), (\"2\", \"Under\"), (\"3\", \"Under\"),\n",
    "        (\"4\", \"Under\"), (\"5\", \"Under\"), (\"6\", \"Under\"), \n",
    "        (\"1\", \"Over\"), (\"2\", \"Over\"), (\"3\", \"Over\"), \n",
    "        (\"4\", \"Over\"), (\"5\", \"Over\"), (\"6\", \"Over\")]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure_six(comp_df):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    colorlist = ['#001c7f', #Original\n",
    "                 '#12711c', \n",
    "                 #'#23fab9', \n",
    "                 #'#00875e',\n",
    "                 #'#3fb9c4',\n",
    "                 '#a2ff00']\n",
    "                 #'#688c29']\n",
    "    \n",
    "    data = comp_df.groupby(['Method', 'Mode'])[['value', 'recall_disp']].mean().reindex([\n",
    "        (\"Original\", \"Original\"),\n",
    "        (\"1\", \"Under\"), (\"2\", \"Under\"), (\"3\", \"Under\"),\n",
    "        (\"4\", \"Under\"), (\"5\", \"Under\"), (\"6\", \"Under\"), \n",
    "        (\"1\", \"Over\"), (\"2\", \"Over\"), (\"3\", \"Over\"), \n",
    "        (\"4\", \"Over\"), (\"5\", \"Over\"), (\"6\", \"Over\")]).reset_index()\n",
    "    \n",
    "    sns.lineplot(data = data,\n",
    "                 x='value', y='recall_disp',\n",
    "                 hue = 'Mode',\n",
    "                 style = 'Method',\n",
    "                 markers = True,\n",
    "                 palette = colorlist,\n",
    "                 color = colorlist,\n",
    "                 markersize = 10,\n",
    "                 dashes = None,\n",
    "                 ci = None,\n",
    "                 ax = ax)\n",
    "    \n",
    "    unique_dfs = [(\"Original\",\"Original\"),\n",
    "                  (\"1\",\"Under\"), (\"1\",\"Over\"),\n",
    "                  (\"2\",\"Under\"),(\"2\",\"Over\"),\n",
    "                  (\"3\",\"Under\"),(\"3\",\"Over\"),\n",
    "                  (\"4\",\"Under\"),(\"4\",\"Over\"),\n",
    "                  (\"5\",\"Under\"),(\"5\",\"Over\"),\n",
    "                  (\"6\",\"Under\"),(\"6\",\"Over\")]\n",
    "    \n",
    "    \n",
    "    for i in range(len(unique_dfs)):\n",
    "        tmp_df = comp_df.loc[(comp_df['Method'] == unique_dfs[i][0]) & (comp_df['Mode']==unique_dfs[i][1]), ].copy()\n",
    "        \n",
    "        x_coords = list(tmp_df.groupby(['Method', 'Mode'])[['value', 'recall_disp']].mean().reset_index()['value'].values)\n",
    "        y_coords = list(tmp_df.groupby(['Method', 'Mode'])[['value', 'recall_disp']].mean().reset_index()['recall_disp'].values)\n",
    "        \n",
    "        \n",
    "        prec_errors = 1.96*tmp_df.groupby(['Method', 'Mode'])['value'].sem().values\n",
    "        disp_errors = 1.96*tmp_df.groupby(['Method', 'Mode'])['recall_disp'].sem().values\n",
    "    \n",
    "        mode = unique_dfs[i][1]\n",
    "        if mode == \"Original\":\n",
    "            color = colorlist[0]\n",
    "        elif mode == \"Under\":\n",
    "            color = colorlist[1]\n",
    "        else:\n",
    "            color = colorlist[2]\n",
    "            \n",
    "        ax.errorbar(x_coords, y_coords,\n",
    "                   xerr = prec_errors,\n",
    "                   yerr = disp_errors,\n",
    "                   ecolor = color, fmt= ' ', zorder=-1, capsize=5)\n",
    "        \n",
    "    ax.set_ylabel('', fontsize=32)\n",
    "    ax.set_xlabel('Precision at Top-K', fontsize=28)\n",
    "    ax.plot([0.0,1.0],[1.0, 1.0], linestyle = '--', color='black')\n",
    "    \n",
    "    ax.tick_params(axis='x', labelsize=24)\n",
    "    ax.tick_params(axis='y', labelsize=24)\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    hhandles = []\n",
    "    llabels = []\n",
    "\n",
    "    #for i, lab in enumerate(labels):\n",
    "    #    if lab not in list(unique_dfs):\n",
    "    #        handles[i].set_linestyle(\"\")\n",
    "    #        lab = \"Methods\"\n",
    "    #    hhandles.append(handles[i])\n",
    "    #    llabels.append(lab)\n",
    "\n",
    "    ax.legend(handles, labels, fontsize=18, \n",
    "              bbox_to_anchor=(0.015, 0.985), \n",
    "              loc='upper left', \n",
    "              borderaxespad=0., markerscale=2, ncol=1)\n",
    "    \n",
    "    ax.plot([0.1, 0.9], [1.0, 1.0], color='black', linestyle='--')\n",
    "    ax.set_xlim([0.735, 0.82])\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_six(fig_six_df)\n",
    "plt.savefig('../../PLOTS2/PLOTS_Sampling/SanJose_Sampling.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_seven_df = pd.concat([filtered_orig_df, filtered_adjusted_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure_seven(comp_df):\n",
    "    colorlist = sns.color_palette(\"dark\", 12).as_hex()\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    data = comp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reindex([\"Original\", \"Post-hoc Adjustment\"]\n",
    "                                                                                ).reset_index()\n",
    "\n",
    "    colorlist = ['#001c7f', #Original\n",
    "                '#a23582']\n",
    "\n",
    "    sns.lineplot(data = data,\n",
    "                 x='value', y='recall_disp',\n",
    "                 hue = 'dataset',\n",
    "                 markers = True,\n",
    "                 palette = colorlist,\n",
    "                 marker = \"o\",\n",
    "                 markersize = 10,\n",
    "                 dashes = None,\n",
    "                 ci = None,\n",
    "                 ax = ax)\n",
    "    \n",
    "    unique_dfs = [\"Original\", \"Post-hoc Adjustment\"]\n",
    "    \n",
    "    for i in range(len(unique_dfs)):\n",
    "        tmp_df = comp_df.loc[comp_df['dataset'] == unique_dfs[i], ].copy()\n",
    "        \n",
    "        x_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['value'].values)\n",
    "        y_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['recall_disp'].values)\n",
    "        \n",
    "        prec_errors = 1.96*tmp_df.groupby(['dataset'])['value'].sem().values\n",
    "        disp_errors = 1.96*tmp_df.groupby(['dataset'])['recall_disp'].sem().values\n",
    "        \n",
    "        color = colorlist[i]\n",
    "        \n",
    "        ax.errorbar(x_coords, y_coords,\n",
    "                   xerr = prec_errors,\n",
    "                   yerr = disp_errors,\n",
    "                   ecolor = colorlist[i], fmt= ' ', zorder=-1, capsize=5)\n",
    "        \n",
    "    ax.set_ylabel('', fontsize=32)\n",
    "    ax.set_xlabel('Precision at Top-K', fontsize=28)\n",
    "    ax.plot([0.0,1.0],[1.0, 1.0], linestyle = '--', color='black')\n",
    "    \n",
    "    ax.tick_params(axis='x', labelsize=24)\n",
    "    ax.tick_params(axis='y', labelsize=24)\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    hhandles = []\n",
    "    llabels = []\n",
    "\n",
    "    for i, lab in enumerate(labels):\n",
    "        #if lab not in list(unique_dfs):# + ['dataset']:\n",
    "        #    handles[i].set_linestyle(\"\")\n",
    "        if lab not in list(unique_dfs):\n",
    "            handles[i].set_linestyle(\"\")\n",
    "            lab = \"Methods\"\n",
    "        hhandles.append(handles[i])\n",
    "        llabels.append(lab)\n",
    "    \n",
    "    llabels = ['Methods', 'Original', 'Post-hoc\\nAdjustment']\n",
    "    ax.legend(hhandles[1:], llabels[1:], fontsize=20, \n",
    "              bbox_to_anchor=(0.01, 0.985), \n",
    "              loc='upper left', \n",
    "              borderaxespad=0., markerscale=2, ncol=1)    \n",
    "    ax.set_ylim([0.9, 2.0])\n",
    "    ax.set_xlim([0.75, 0.82])\n",
    "    ax.plot([0.1, 0.9], [1.0, 1.0], color='black', linestyle='--')\n",
    "    #ax.legend().remove()\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_seven(fig_seven_df)\n",
    "plt.savefig('../../PLOTS2/PLOTS_Post/sanjose_post.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_one_df = pd.concat([filtered_orig_df, filtered_nop_df, filtered_zafar_df, best_usamp_prec_df, \n",
    "                       best_usamp_equity_df, best_osamp_prec_df, best_osamp_equity_df, dec_df])\n",
    "\n",
    "fig_one_df.loc[fig_one_df['strategy']=='Best Unadjusted Metric - Unadjusted', 'strategy'] = 'No Adjustment'\n",
    "fig_one_df.loc[fig_one_df['strategy']=='Best Unadjusted Metric - Adjusted', 'strategy'] = 'Adjusted'\n",
    "fig_one_df.loc[fig_one_df['strategy']=='Composite w/ Decoupled - Adjusted','strategy'] = 'Decoupled Adjusted'\n",
    "fig_one_df.loc[fig_one_df['strategy']=='Composite Model - Adjusted','strategy'] = 'Composite Adjusted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(fig_one_df)\n",
    "plt.savefig('../../PLOTS2/San_Jose_Summary.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_three_df = pd.concat([orig_df, nop_df])\n",
    "filtered_orig_df = orig_df[(orig_df['strategy'] == 'Best Unadjusted Metric - Unadjusted')]\n",
    "filtered_nop_df = nop_df[nop_df['strategy'] == 'Best Unadjusted Metric - Unadjusted']\n",
    "\n",
    "fig_three_df = pd.concat([filtered_orig_df, filtered_nop_df])\n",
    "fig_three_df.loc[fig_three_df['strategy']=='Best Unadjusted Metric - Unadjusted', 'strategy'] = 'No Adjustment'\n",
    "fig_three_df.loc[(fig_three_df['dataset']=='NoP'),'dataset'] = 'No Protected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure_three(comp_df):\n",
    "    colorlist = sns.color_palette(\"dark\", 12).as_hex()\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    #data = comp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()\n",
    "    data = comp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reindex([\"Original\", \"No Protected\"]\n",
    "                                                                                ).reset_index()\n",
    "    colorlist = ['#001c7f', #Original\n",
    "                 '#b1400d', #No_Protected\n",
    "                 '#12711c', #Best Sampling(Equity)\n",
    "                 '#8c0800', #Best Sampling(Precision)\n",
    "                 '#591e71', #Composite Adjustment\n",
    "                 '#592f0d', #Regularization\n",
    "                 '#a23582', #Post-hoc Adjustment\n",
    "                 '#3c3c3c', \n",
    "                 '#b8850a', \n",
    "                 '#006374', \n",
    "                 '#001c7f', \n",
    "                 '#b1400d']\n",
    "\n",
    "    unique_dfs = [\"Original\", \"No Protected\"]\n",
    "    \n",
    "    sns.lineplot(data = data,\n",
    "                 x='value', y='recall_disp',\n",
    "                 hue = 'dataset',\n",
    "                 markers = True,\n",
    "                 color = colorlist,\n",
    "                 marker = \"o\",\n",
    "                 markersize = 10,\n",
    "                 dashes = None,\n",
    "                 ci = None,\n",
    "                 ax = ax)\n",
    "    \n",
    "    unique_dfs = [\"Original\", \"No Protected\"]\n",
    "    #unique_dfs = np.unique(data['dataset'])\n",
    "    \n",
    "    for i in range(len(unique_dfs)):\n",
    "            sns.lineplot(data = data,\n",
    "                 x='value', y='recall_disp',\n",
    "                 hue = 'dataset',\n",
    "                 markers = True,\n",
    "                 color = colorlist,\n",
    "                 linewidth = 20.0,\n",
    "                 marker = \"o\",\n",
    "                 markersize = 10,\n",
    "                 dashes = None,\n",
    "                 ci = None,\n",
    "                 ax = ax)\n",
    "    \n",
    "    #unique_dfs = np.unique(data['dataset'])\n",
    "    \n",
    "    for i in range(len(unique_dfs)):\n",
    "        tmp_df = comp_df.loc[comp_df['dataset'] == unique_dfs[i], ].copy()\n",
    "        \n",
    "        x_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['value'].values)\n",
    "        y_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['recall_disp'].values)\n",
    "        \n",
    "        prec_errors = 1.96*tmp_df.groupby(['dataset'])['value'].sem().values\n",
    "        disp_errors = 1.96*tmp_df.groupby(['dataset'])['recall_disp'].sem().values\n",
    "        \n",
    "        color = colorlist[i]\n",
    "        \n",
    "        ax.errorbar(x_coords, y_coords,\n",
    "                   xerr = prec_errors,\n",
    "                   yerr = disp_errors,\n",
    "                   ecolor = colorlist[i], fmt= ' ', zorder=-1, capsize=5, linewidth=3.0)\n",
    "        \n",
    "        \n",
    "    ax.set_ylabel('Recall Disparity', fontsize=20)\n",
    "    ax.set_xlabel('Precision at Top-K', fontsize=20)\n",
    "    \n",
    "    ax.tick_params(axis='x', labelsize=16)\n",
    "    ax.tick_params(axis='y', labelsize=16)\n",
    "    ax.get_legend().remove()\n",
    "    \n",
    "    '''\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    hhandles = []\n",
    "    llabels = []\n",
    "\n",
    "    for i, lab in enumerate(labels):\n",
    "        #if lab not in list(unique_dfs):# + ['dataset']:\n",
    "        #    handles[i].set_linestyle(\"\")\n",
    "        if lab not in list(unique_dfs):\n",
    "            handles[i].set_linestyle(\"\")\n",
    "            lab = \"Methods\"\n",
    "        hhandles.append(handles[i])\n",
    "        llabels.append(lab)\n",
    "\n",
    "    ax.legend(hhandles, llabels, fontsize=16, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., markerscale=2)\n",
    "    '''\n",
    "    #ax.set_ylim([0.9, 2.2])\n",
    "    ax.set_xlim([0.77, 0.82])\n",
    "    ax.plot([0.0, 1.0], [1.0, 1.0], color='black', linestyle='--')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_three(fig_three_df)\n",
    "plt.savefig('../../PLOTS2/PLOTS_NOP/NoP_SanJose.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_four_df = pd.concat([orig_df, zafar_df])\n",
    "filtered_orig_df = orig_df[(orig_df['strategy'] == 'Best Unadjusted Metric - Unadjusted')]\n",
    "filtered_zafar_df = zafar_df[zafar_df['strategy'] == 'Best Unadjusted Metric - Unadjusted']\n",
    "\n",
    "fig_four_df = pd.concat([filtered_orig_df, filtered_zafar_df])\n",
    "fig_four_df.loc[fig_four_df['strategy']=='Best Unadjusted Metric - Unadjusted', 'strategy'] = 'Original'\n",
    "fig_four_df.loc[(fig_four_df['dataset']=='Zafar'),'dataset'] = 'Regularization'\n",
    "\n",
    "pd.value_counts(fig_four_df['dataset'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure_four(comp_df):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    data = comp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reindex([\"Original\", \"Regularization\"]\n",
    "                                                                                ).reset_index()\n",
    "    colorlist = ['#001c7f', '#592f0d'] #Regularization\n",
    "    \n",
    "    unique_dfs = [\"Original\", \"Regularization\"]\n",
    "\n",
    "    sns.lineplot(data = data,\n",
    "                 x='value', y='recall_disp',\n",
    "                 hue = 'dataset',\n",
    "                 markers = True,\n",
    "                 palette = colorlist,\n",
    "                 linewidth = 20.0,\n",
    "                 marker = \"o\",\n",
    "                 markersize = 10,\n",
    "                 dashes = None,\n",
    "                 ci = None,\n",
    "                 ax = ax)\n",
    "    \n",
    "    for i in range(len(unique_dfs)):\n",
    "        tmp_df = comp_df.loc[comp_df['dataset'] == unique_dfs[i], ].copy()        \n",
    "        x_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['value'].values)\n",
    "        y_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['recall_disp'].values)\n",
    "        \n",
    "        prec_errors = 1.96*tmp_df.groupby(['dataset'])['value'].sem().values\n",
    "        disp_errors = 1.96*tmp_df.groupby(['dataset'])['recall_disp'].sem().values\n",
    "        \n",
    "        color = colorlist[i]\n",
    "    \n",
    "        ax.errorbar(x_coords, y_coords,\n",
    "                   xerr = prec_errors,\n",
    "                   yerr = disp_errors,\n",
    "                   ecolor = colorlist[i], fmt= ' ', zorder=-1, capsize=5, linewidth=3.0)\n",
    "        \n",
    "    ax.set_ylabel('Recall Disparity', fontsize=20)\n",
    "    ax.set_xlabel('Precision at Top-K', fontsize=20)\n",
    "    \n",
    "    ax.tick_params(axis='x', labelsize=16)\n",
    "    ax.tick_params(axis='y', labelsize=16)\n",
    "    ax.get_legend().remove()\n",
    "    \n",
    "    '''\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    hhandles = []\n",
    "    llabels = []\n",
    "\n",
    "    for i, lab in enumerate(labels):\n",
    "        #if lab not in list(unique_dfs):# + ['dataset']:\n",
    "        #    handles[i].set_linestyle(\"\")\n",
    "        if lab not in list(unique_dfs):\n",
    "            handles[i].set_linestyle(\"\")\n",
    "            lab = \"Methods\"\n",
    "        hhandles.append(handles[i])\n",
    "        llabels.append(lab)\n",
    "\n",
    "    ax.legend(hhandles, llabels, fontsize=16, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., markerscale=2)\n",
    "    '''\n",
    "    ax.set_ylim([0.9, 2.0])\n",
    "    ax.set_xlim([0.74, 0.81])\n",
    "    ax.plot([0.0, 1.0], [1.0, 1.0], color='black', linestyle='--')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_four(fig_four_df)\n",
    "plt.savefig('../../PLOTS2/PLOTS_Zafar/sanjose_zafar.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoupled_df = dec_df\n",
    "filtered_orig_df = orig_df[(orig_df['strategy'] == 'Best Unadjusted Metric - Unadjusted') |\n",
    "                           (orig_df['strategy'] == 'Composite Model - Adjusted')]\n",
    "filtered_decoupled_df = decoupled_df[(decoupled_df['strategy'] == 'Composite w/ Decoupled - Adjusted')]\n",
    "\n",
    "fig_five_df = pd.concat([filtered_orig_df, filtered_decoupled_df])\n",
    "fig_five_df.loc[fig_five_df['strategy']=='Best Unadjusted Metric - Unadjusted', 'strategy'] = 'No Adjustment'\n",
    "fig_five_df.loc[fig_five_df['strategy']=='Composite Model - Adjusted', 'dataset'] = 'Composite'\n",
    "fig_five_df.loc[fig_five_df['strategy']=='Composite Model - Adjusted', 'strategy'] = 'Adjustment'\n",
    "fig_five_df.loc[fig_five_df['dataset']=='DeCoupled','dataset'] = 'Decoupled'\n",
    "pd.value_counts(fig_five_df['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure_five(comp_df):\n",
    "    colorlist = sns.color_palette(\"dark\", 12).as_hex()\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    data = comp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reindex([\"Original\", \"Composite\", \"Decoupled\"]\n",
    "                                                                                ).reset_index()\n",
    "\n",
    "    colorlist = ['#001c7f', #Original\n",
    "                 '#591e71', # Composite Adjustment\n",
    "                 '#3c3c3c' # Decoupled\n",
    "                ]\n",
    "\n",
    "    sns.lineplot(data = data,\n",
    "                 x='value', y='recall_disp',\n",
    "                 hue = 'dataset',\n",
    "                 markers = True,\n",
    "                 palette = colorlist,\n",
    "                 marker = \"o\",\n",
    "                 markersize = 10,\n",
    "                 dashes = None,\n",
    "                 ci = None,\n",
    "                 ax = ax)\n",
    "    \n",
    "    unique_dfs = [\"Original\", \"Composite\", \"Decoupled\"]\n",
    "    \n",
    "    for i in range(len(unique_dfs)):\n",
    "        tmp_df = comp_df.loc[comp_df['dataset'] == unique_dfs[i], ].copy()\n",
    "        \n",
    "        x_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['value'].values)\n",
    "        y_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['recall_disp'].values)\n",
    "        \n",
    "        prec_errors = 1.96*tmp_df.groupby(['dataset'])['value'].sem().values\n",
    "        disp_errors = 1.96*tmp_df.groupby(['dataset'])['recall_disp'].sem().values\n",
    "        \n",
    "        color = colorlist[i]\n",
    "        \n",
    "        ax.errorbar(x_coords, y_coords,\n",
    "                   xerr = prec_errors,\n",
    "                   yerr = disp_errors,\n",
    "                   ecolor = colorlist[i], fmt= ' ', zorder=-1, capsize=5)\n",
    "        \n",
    "    ax.set_ylabel('Recall Disparity', fontsize=16)\n",
    "    ax.set_xlabel('Precision at Top-K', fontsize=16)\n",
    "    \n",
    "    ax.tick_params(axis='x', labelsize=16)\n",
    "    ax.tick_params(axis='y', labelsize=16)\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    hhandles = []\n",
    "    llabels = []\n",
    "\n",
    "    for i, lab in enumerate(labels):\n",
    "        if lab not in list(unique_dfs):\n",
    "            handles[i].set_linestyle(\"\")\n",
    "            lab = \"Methods\"\n",
    "        hhandles.append(handles[i])\n",
    "        llabels.append(lab)\n",
    "\n",
    "    ax.legend(hhandles, llabels, fontsize=16, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., markerscale=2)\n",
    "    ax.set_ylim([0.6, 2.0])\n",
    "    ax.set_xlim([0.7, 0.82])\n",
    "    ax.plot([0.1, 0.9], [1.0, 1.0], color='black', linestyle='--')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_five(fig_five_df)\n",
    "plt.savefig('../../PLOTS2/PLOTS_Composite/Composite_SanJose.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode(x):\n",
    "    if \"Original\" in x:\n",
    "        return \"Original\"\n",
    "    elif \"U\" in x:\n",
    "        return \"Under\"\n",
    "    return \"Over\"\n",
    "\n",
    "usamp_df = under_df\n",
    "osamp_df = over_df\n",
    "\n",
    "filtered_orig_df = orig_df[(orig_df['strategy'] == 'Best Unadjusted Metric - Unadjusted')]\n",
    "filtered_usamp_df = usamp_df[(usamp_df['strategy'] == 'Best Unadjusted Metric - Unadjusted')]\n",
    "filtered_osamp_df = osamp_df[(osamp_df['strategy'] == 'Best Unadjusted Metric - Unadjusted')]\n",
    "fig_six_df = pd.concat([filtered_orig_df, filtered_usamp_df, filtered_osamp_df])\n",
    "\n",
    "fig_six_df.loc[fig_six_df['strategy']=='Best Unadjusted Metric - Unadjusted', 'strategy'] = 'No Adjustment'\n",
    "\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Original', 'mode'] = 'Original'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v1a', 'mode'] = 'Under'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v1a', 'dataset'] = '1'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v2a', 'mode'] = 'Under'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v2a', 'dataset'] = '2'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v2b', 'mode'] = 'Under'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v2b', 'dataset'] = '3'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v2c', 'mode'] = 'Under'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v2c', 'dataset'] = '4'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v3a', 'mode'] = 'Under'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v3a', 'dataset'] = '5'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v3b', 'mode'] = 'Under'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Under-v3b', 'dataset'] = '6'\n",
    "\n",
    "fig_six_df.loc[fig_six_df['strategy']=='Best Unadjusted Metric - Unadjusted', 'strategy'] = 'No Adjustment'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v1a', 'mode'] = 'Over'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v1a', 'dataset'] = '1'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v2a', 'mode'] = 'Over'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v2a', 'dataset'] = '2'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v2b', 'mode'] = 'Over'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v2b', 'dataset'] = '3'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v2c', 'mode'] = 'Over'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v2c', 'dataset'] = '4'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v3a', 'mode'] = 'Over'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v3a', 'dataset'] = '5'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v3b', 'mode'] = 'Over'\n",
    "fig_six_df.loc[fig_six_df['dataset']=='Over-v3b', 'dataset'] = '6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(fig_six_df['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure_six(comp_df):\n",
    "    colorlist = sns.color_palette(\"dark\", 14).as_hex()\n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    \n",
    "    data = comp_df.groupby(['dataset', 'mode'])[['value', 'recall_disp']].mean().reindex([\n",
    "        (\"Original\", \"Original\"),\n",
    "        (\"1\", \"Under\"), (\"2\", \"Under\"), (\"3\", \"Under\"),\n",
    "        (\"4\", \"Under\"), \n",
    "        (\"5\", \"Under\"), (\"6\", \"Under\"), \n",
    "        (\"1\", \"Over\"), (\"2\", \"Over\"), (\"3\", \"Over\"), \n",
    "        (\"4\", \"Over\"), \n",
    "        (\"5\", \"Over\"), (\"6\", \"Over\")]).reset_index()\n",
    "    \n",
    "    sns.lineplot(data = data,\n",
    "                 x='value', y='recall_disp',\n",
    "                 hue = 'dataset',\n",
    "                 style = 'mode',\n",
    "                 markers = True,\n",
    "                 color = colorlist,\n",
    "                 markersize = 10,\n",
    "                 dashes = None,\n",
    "                 ci = None,\n",
    "                 ax = ax)\n",
    "    \n",
    "    unique_dfs = [\"Original\", \"1\", \"2\", \"3\", \n",
    "                  \"4\", \n",
    "                  \"5\", \"6\"]\n",
    "    \n",
    "    for i in range(len(unique_dfs)):\n",
    "        tmp_df = comp_df.loc[comp_df['dataset'] == unique_dfs[i], ].copy()\n",
    "        \n",
    "        x_coords = list(tmp_df.groupby(['dataset', 'mode'])[['value', 'recall_disp']].mean().reset_index()['value'].values)\n",
    "        y_coords = list(tmp_df.groupby(['dataset', 'mode'])[['value', 'recall_disp']].mean().reset_index()['recall_disp'].values)\n",
    "        \n",
    "        prec_errors = 1.96*tmp_df.groupby(['dataset', 'mode'])['value'].sem().values\n",
    "        disp_errors = 1.96*tmp_df.groupby(['dataset', 'mode'])['recall_disp'].sem().values\n",
    "        \n",
    "        color = colorlist[i]\n",
    "        \n",
    "        ax.errorbar(x_coords, y_coords,\n",
    "                   xerr = prec_errors,\n",
    "                   yerr = disp_errors,\n",
    "                   ecolor = colorlist[i], fmt= ' ', zorder=-1, capsize=5)\n",
    "        \n",
    "    ax.set_ylabel('Recall Disparity', fontsize=16)\n",
    "    ax.set_xlabel('Precision at Top-K', fontsize=16)\n",
    "    \n",
    "    ax.tick_params(axis='x', labelsize=16)\n",
    "    ax.tick_params(axis='y', labelsize=16)\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    hhandles = []\n",
    "    llabels = []\n",
    "    for i, lab in enumerate(labels):\n",
    "        if lab not in list(unique_dfs) + ['dataset', 'mode']:\n",
    "            handles[i].set_linestyle(\"\")\n",
    "        hhandles.append(handles[i])\n",
    "        llabels.append(lab)\n",
    "        \n",
    "    ax.legend(hhandles, llabels, fontsize=16, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., markerscale=2)\n",
    "    ax.plot([0.1, 0.9], [1.0, 1.0], color='black', linestyle='--')\n",
    "    ax.set_xlim([0.74, 0.82])\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure_six(fig_six_df)\n",
    "plt.savefig('../../PLOTS2/PLOTS_Sampling/SanJose_Sampling.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure_seven(comp_df):\n",
    "    colorlist = sns.color_palette(\"dark\", 12).as_hex()\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    \n",
    "    #data = comp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()\n",
    "    data = comp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reindex([\"Original\", \"Adjusted\"]).reset_index()\n",
    "\n",
    "    sns.lineplot(data = data,\n",
    "                 x='value', y='recall_disp',\n",
    "                 hue = 'dataset',\n",
    "                 markers = True,\n",
    "                 color = colorlist,\n",
    "                 marker = \"o\",\n",
    "                 markersize = 10,\n",
    "                 dashes = None,\n",
    "                 ci = None,\n",
    "                 ax = ax)\n",
    "    \n",
    "    unique_dfs = [\"Original\", \"Adjusted\"]\n",
    "    \n",
    "    for i in range(len(unique_dfs)):\n",
    "        tmp_df = comp_df.loc[comp_df['dataset'] == unique_dfs[i], ].copy()\n",
    "        \n",
    "        x_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['value'].values)\n",
    "        y_coords = list(tmp_df.groupby(['dataset'])[['value', 'recall_disp']].mean().reset_index()['recall_disp'].values)\n",
    "        \n",
    "        prec_errors = 1.96*tmp_df.groupby(['dataset'])['value'].sem().values\n",
    "        disp_errors = 1.96*tmp_df.groupby(['dataset'])['recall_disp'].sem().values\n",
    "        \n",
    "        color = colorlist[i]\n",
    "        \n",
    "        ax.errorbar(x_coords, y_coords,\n",
    "                   xerr = prec_errors,\n",
    "                   yerr = disp_errors,\n",
    "                   ecolor = colorlist[i], fmt= ' ', zorder=-1, capsize=5)\n",
    "        \n",
    "    ax.set_ylabel('Recall Disparity', fontsize=16)\n",
    "    ax.set_xlabel('Precision at Top-K', fontsize=16)\n",
    "    \n",
    "    ax.tick_params(axis='x', labelsize=16)\n",
    "    ax.tick_params(axis='y', labelsize=16)\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    hhandles = []\n",
    "    llabels = []\n",
    "\n",
    "    for i, lab in enumerate(labels):\n",
    "        #if lab not in list(unique_dfs):# + ['dataset']:\n",
    "        #    handles[i].set_linestyle(\"\")\n",
    "        if lab not in list(unique_dfs):\n",
    "            handles[i].set_linestyle(\"\")\n",
    "            lab = \"Methods\"\n",
    "        hhandles.append(handles[i])\n",
    "        llabels.append(lab)\n",
    "\n",
    "    ax.legend(hhandles, llabels, fontsize=16, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., markerscale=2)\n",
    "    ax.set_xlim([0.77, 0.83])\n",
    "    ax.plot([0.1, 0.9], [1.0, 1.0], color='black', linestyle='--')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_orig_df = orig_df[(orig_df['strategy'] == 'Best Unadjusted Metric - Unadjusted')|\n",
    "                          (orig_df['strategy'] == 'Best Unadjusted Metric - Adjusted')]\n",
    "fig_seven_df = pd.concat([filtered_orig_df])\n",
    "\n",
    "fig_seven_df.loc[fig_seven_df['strategy']=='Best Unadjusted Metric - Unadjusted', 'strategy'] = 'No Adjustment'\n",
    "fig_seven_df.loc[fig_seven_df['strategy']=='Best Unadjusted Metric - Adjusted', 'strategy'] = 'Adjusted'\n",
    "\n",
    "fig_seven_df.loc[fig_seven_df['strategy']=='No Adjustment', 'dataset'] = 'Original'\n",
    "fig_seven_df.loc[fig_seven_df['strategy']=='Adjusted', 'dataset'] = 'Adjusted'\n",
    "\n",
    "plot_figure_seven(fig_seven_df)\n",
    "plt.savefig('../../PLOTS2/PLOTS_Post/san_jose_post.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
